{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wenwei/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/wenwei/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, KFold, TimeSeriesSplit\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, roc_auc_score, mean_squared_error, \n",
    "                             confusion_matrix, classification_report)\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "import shap\n",
    "import itertools\n",
    "import math\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "import re\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# LightGBM and XGBoost\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from xgboost import DMatrix\n",
    "\n",
    "# TensorFlow / Keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "# Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Displaying Images\n",
    "from IPython.display import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "# Ignore Warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df = pd.read_csv(\"cleaned data/cleaned_data_split.csv\")\n",
    "\n",
    "mds = df[df['X_fold'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    with open(model_path, 'rb') as f:\n",
    "        return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features.astype('float32').values, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels.values, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'features': self.features[idx],\n",
    "            'label': self.labels[idx]\n",
    "        }\n",
    "\n",
    "class AccountTypeClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=[128, 64], num_classes=2, dropout_rate=0.3):\n",
    "        super(AccountTypeClassifier, self).__init__()\n",
    "        \n",
    "        # Build layers dynamically\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        # Output layer\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.output = nn.Linear(prev_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return self.output(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelrf = load_model('output_files/{0}_best_model.pkl'.format('rf'))\n",
    "modelxgb = load_model('output_files/{0}_best_model.pkl'.format('xgb'))\n",
    "modellgbm = load_model('output_files/{0}_best_model.pkl'.format('lgbm'))\n",
    "modelnn = load_model('output_files/{0}_best_model.pkl'.format('nn'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive_cols_log = ['default_profile', 'default_profile_image',\n",
    "        'geo_enabled', 'deviation_from_humans', 'location', 'verified',\n",
    "        'account_age_days', 'is_description_na', 'is_lang_na', 'is_lang_en',\n",
    "       'is_location_unknown', 'creation_hour', 'creation_day_of_week',\n",
    "       'creation_month', 'creation_year', 'is_weekend', 'creation_quarter',\n",
    "       'part_of_day', 'creation_week_of_year', 'is_beginning_of_month',\n",
    "       'is_end_of_month', 'description_length', 'influencer_type',\n",
    "       'favourites_per_day', 'favourites_activity',\n",
    "       'mention_count', 'log_favourites_count', 'log_followers_count', 'log_friends_count',\n",
    "       'log_statuses_count', 'log_average_tweets_per_day',\n",
    "       'log_fol_to_friends_ratio', 'log_fol_to_tweets_ratio',\n",
    "       'log_friends_to_tweets_ratio', 'sentiment_label', 'account_type']\n",
    "\n",
    "features = [col for col in predictive_cols_log if col not in ['id', 'account_type', 'X_fold']]\n",
    "target = ['account_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembling Method for Model Combination\n",
    "\n",
    "The ensembling method aims to combine multiple predictive models, specifically traditional models (XGBoost, LightGBM, and optionally RandomForest) and a neural network model, to improve performance. The ensemble strategy involves weighted averaging of the predictions from the traditional models and the neural network model. Below is a summary of the approach:\n",
    "\n",
    "1. **Model Pairing**:\n",
    "   - The ensemble combines two types of models: traditional machine learning models (XGBoost, LightGBM, etc.) and a neural network model. These models are paired in various combinations for testing.\n",
    "   - In this example, the models used are:\n",
    "     - XGBoost (`modelxgb`)\n",
    "     - LightGBM (`modellgbm`)\n",
    "     - Neural Network (`modelnn`)\n",
    "\n",
    "2. **Weighting**:\n",
    "   - Different weight combinations are tested for the ensemble predictions. The weights determine how much influence each model's predictions have in the final combined prediction. In the example, the following weight combinations are considered:\n",
    "     - (0.7, 0.3)\n",
    "     - (0.5, 0.5)\n",
    "     - (0.3, 0.7)\n",
    "   - `w1` and `w2` correspond to the weights assigned to the traditional model predictions and neural network predictions, respectively.\n",
    "\n",
    "3. **Prediction Process**:\n",
    "   - For each model, out-of-fold predictions are generated using 5-fold cross-validation.\n",
    "   - For neural network predictions, the model outputs probabilities (for binary classification) that are used in the ensemble.\n",
    "\n",
    "4. **Ensemble Calculation**:\n",
    "   - The predictions from the traditional model (`preds`) and the neural network (`nn_preds`) are combined using the weighted average formula:\n",
    "     \\[\n",
    "     \\text{ensemble\\_preds} = (w1 \\times \\text{preds}) + (w2 \\times \\text{nn\\_preds})\n",
    "     \\]\n",
    "   - The combined prediction is then thresholded (at 0.5) to convert probabilities into binary labels (0 or 1).\n",
    "\n",
    "5. **Metrics**:\n",
    "   - The performance of the ensemble is evaluated using several classification metrics:\n",
    "     - **Accuracy**: The proportion of correct predictions.\n",
    "     - **AUC (Area Under the Curve)**: A measure of the model's ability to distinguish between the classes.\n",
    "     - **Recall**: The proportion of actual positives correctly identified by the model.\n",
    "     - **Precision**: The proportion of predicted positives that are actually correct.\n",
    "     - **F1-Score**: The harmonic mean of precision and recall.\n",
    "\n",
    "6. **Best Model and Weight Combination**:\n",
    "   - After testing all combinations, the best model and weight combination is selected based on the highest F1-Score. This combination is considered the most balanced, ensuring both high precision and recall.\n",
    "\n",
    "7. **Output**:\n",
    "   - The model, weight combination, and corresponding metrics (Accuracy, AUC, Recall, Precision, F1-Score) are printed for each iteration.\n",
    "   - Finally, the best model and weight combination are displayed, showing the highest performance across the evaluated metrics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Define weight combinations and model pairs\n",
    "weights = [(0.7, 0.3), (0.5, 0.5), (0.3, 0.7)]\n",
    "model_pairs = [('XGBoost', modelxgb), ('LightGBM', modellgbm)]\n",
    "#model_pairs = [('RandomForest', modelrf), ('XGBoost', modelxgb), ('LightGBM', modellgbm)]\n",
    "nn_model = modelnn  # Neural network model instance\n",
    "\n",
    "# Prepare the data\n",
    "X = mds[features]\n",
    "y = mds[target]\n",
    "X_tensor = torch.tensor(X.values, dtype=torch.float32)  # Convert X to a tensor for NN model\n",
    "\n",
    "# Get predictions from the neural network model\n",
    "with torch.no_grad():\n",
    "    nn_outputs = nn_model(X_tensor).numpy()  # Assuming nn_model outputs probabilities\n",
    "    nn_preds = nn_outputs[:, 1]  # Adjust index for binary classification\n",
    "\n",
    "# Initialize variables to track the best combination and metrics\n",
    "best_combination = None\n",
    "best_metrics = {}\n",
    "\n",
    "# Iterate through each model pair\n",
    "for model_name, model in model_pairs:\n",
    "    # Get out-of-fold predictions for the chosen traditional model\n",
    "    try:\n",
    "        preds = cross_val_predict(model, X, y, cv=5, method='predict_proba')[:, 1]\n",
    "    except IndexError:\n",
    "        preds = cross_val_predict(model, X, y, cv=5, method='predict')\n",
    "    \n",
    "    # Iterate through each weight combination\n",
    "    for w1, w2 in weights:\n",
    "        # Weighted averaging of probabilities\n",
    "        ensemble_preds = (w1 * preds + w2 * nn_preds)\n",
    "        binary_preds = (ensemble_preds >= 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y, binary_preds)\n",
    "        auc = roc_auc_score(y, ensemble_preds) if 'predict_proba' in dir(model) else None\n",
    "        recall = recall_score(y, binary_preds)\n",
    "        precision = precision_score(y, binary_preds)\n",
    "        f1 = f1_score(y, binary_preds)\n",
    "        \n",
    "        print(f\"Model ({model_name}) with Weight ({w1}, {w2}): Accuracy = {accuracy}, AUC = {auc}, Recall = {recall}, Precision = {precision}, F1-Score = {f1}\")\n",
    "        \n",
    "        # Update best metrics based on F1-score\n",
    "        if not best_metrics or f1 > best_metrics['f1']:\n",
    "            best_metrics = {\n",
    "                'model': model_name,\n",
    "                'weight': (w1, w2),\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'recall': recall,\n",
    "                'precision': precision,\n",
    "                'f1': f1\n",
    "            }\n",
    "\n",
    "print(\"\\nBest model and weight combination and metrics:\")\n",
    "print(f\"Model: {best_metrics['model']}\")\n",
    "print(f\"Weight: {best_metrics['weight']}\")\n",
    "print(f\"Accuracy: {best_metrics['accuracy']}\")\n",
    "print(f\"AUC: {best_metrics['auc']}\")\n",
    "print(f\"Recall: {best_metrics['recall']}\")\n",
    "print(f\"Precision: {best_metrics['precision']}\")\n",
    "print(f\"F1-Score: {best_metrics['f1']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE CHUNK BELOW IS FOR TEAM FYI NOT TO BE SUBMITTED\n",
    "\n",
    "The chunk above is an ensemble method used with neural network and tree based models, currently takes too long to run, i have not been able to run it successfully.\n",
    "IF issue persists, we can use the ensemble method below but it only ensembles amongst tree based models does not include neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictproba\n",
      "predict\n",
      "Weight (0.7, 0.3): Accuracy = 0.8546663817511619, AUC = 0.845350696913259, Recall = 0.6844265593561368, Precision = 0.8483639265762171, F1-Score = 0.757628402155998\n",
      "Weight (0.5, 0.5): Accuracy = 0.8621988354078743, AUC = 0.8457285270009696, Recall = 0.7501810865191146, Precision = 0.8193565400843882, F1-Score = 0.7832444014957355\n",
      "Weight (0.3, 0.7): Accuracy = 0.8669266520647471, AUC = 0.8461063570886801, Recall = 0.7244265593561369, Precision = 0.8524481484989109, F1-Score = 0.7832405151409676\n",
      "\n",
      "Best weight combination and metrics:\n",
      "Weight: (0.5, 0.5)\n",
      "Accuracy: 0.8621988354078743\n",
      "AUC: 0.8457285270009696\n",
      "Recall: 0.7501810865191146\n",
      "Precision: 0.8193565400843882\n",
      "F1-Score: 0.7832444014957355\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# Define weight combinations\n",
    "weights = [(0.7, 0.3), (0.5, 0.5), (0.3, 0.7)]\n",
    "\n",
    "\n",
    "model1 = modelrf  # Example model\n",
    "model2 = modelxgb  # Example model\n",
    "\n",
    "# Prepare the data\n",
    "X = mds[features]\n",
    "y = mds[target]\n",
    "\n",
    "# Get out-of-fold predictions for both models (as binary if predict_proba not available)\n",
    "try:\n",
    "    # If models support predict_proba\n",
    "    preds1 = cross_val_predict(model1, X, y, cv=5, method='predict_proba')[:, 1]\n",
    "    preds2 = cross_val_predict(model2, X, y, cv=5, method='predict_proba')[:, 1]\n",
    "except IndexError:\n",
    "    # Use binary predictions instead\n",
    "    preds1 = cross_val_predict(model1, X, y, cv=5, method='predict')\n",
    "    preds2 = cross_val_predict(model2, X, y, cv=5, method='predict')\n",
    "\n",
    "# Initialize variables to track the best weight and metrics\n",
    "best_weight = None\n",
    "best_metrics = {}\n",
    "\n",
    "# Evaluate each weight combination\n",
    "for w1, w2 in weights:\n",
    "    # Apply weighted averaging (if using predict_proba) or majority voting\n",
    "    if 'predict_proba' in dir(model1) and 'predict_proba' in dir(model2):\n",
    "        ensemble_preds = (w1 * preds1 + w2 * preds2)\n",
    "        binary_preds = (ensemble_preds >= 0.5).astype(int)\n",
    "    else:\n",
    "        # Majority voting for binary predictions\n",
    "        ensemble_preds = (w1 * preds1 + w2 * preds2).round().astype(int)\n",
    "        binary_preds = ensemble_preds\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y, binary_preds)\n",
    "    try:\n",
    "        auc = roc_auc_score(y, ensemble_preds)  # Only for probability-based predictions\n",
    "    except ValueError:\n",
    "        auc = None\n",
    "    recall = recall_score(y, binary_preds)\n",
    "    precision = precision_score(y, binary_preds)\n",
    "    f1 = f1_score(y, binary_preds)\n",
    "    \n",
    "    print(f\"Weight ({w1}, {w2}): Accuracy = {accuracy}, AUC = {auc}, Recall = {recall}, Precision = {precision}, F1-Score = {f1}\")\n",
    "\n",
    "    # Update best metrics based on F1-score\n",
    "    if not best_metrics or f1 > best_metrics['f1']:\n",
    "        best_metrics = {\n",
    "            'weight': (w1, w2),\n",
    "            'accuracy': accuracy,\n",
    "            'auc': auc,\n",
    "            'recall': recall,\n",
    "            'precision': precision,\n",
    "            'f1': f1\n",
    "        }\n",
    "\n",
    "print(\"\\nBest weight combination and metrics:\")\n",
    "print(f\"Weight: {best_metrics['weight']}\")\n",
    "print(f\"Accuracy: {best_metrics['accuracy']}\")\n",
    "print(f\"AUC: {best_metrics['auc']}\")\n",
    "print(f\"Recall: {best_metrics['recall']}\")\n",
    "print(f\"Precision: {best_metrics['precision']}\")\n",
    "print(f\"F1-Score: {best_metrics['f1']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
