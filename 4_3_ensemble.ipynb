{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wenwei/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Basic Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, roc_auc_score, classification_report)\n",
    "\n",
    "# LightGBM and XGBoost\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "# PyTorch for Neural Networks\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Neural Network and Custom Dataset\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Ignore Warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df = pd.read_csv(\"cleaned data/cleaned_data_split.csv\")\n",
    "\n",
    "mds = df[df['X_fold'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    with open(model_path, 'rb') as f:\n",
    "        return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features.astype('float32').values, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels.values, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'features': self.features[idx],\n",
    "            'label': self.labels[idx]\n",
    "        }\n",
    "\n",
    "class AccountTypeClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=[128, 64], num_classes=2, dropout_rate=0.3):\n",
    "        super(AccountTypeClassifier, self).__init__()\n",
    "        \n",
    "        # Build layers dynamically\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        # Output layer\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.output = nn.Linear(prev_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return self.output(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelrf = load_model('output_files/{0}_best_model.pkl'.format('rf'))\n",
    "modelxgb = load_model('output_files/{0}_best_model.pkl'.format('xgb'))\n",
    "modellgbm = load_model('output_files/{0}_best_model.pkl'.format('lgbm'))\n",
    "modelnn = load_model('output_files/{0}_best_model.pkl'.format('nn'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive_cols_log = ['default_profile', 'default_profile_image',\n",
    "        'geo_enabled', 'deviation_from_humans', 'location', 'verified',\n",
    "        'account_age_days', 'is_description_na', 'is_lang_na', 'is_lang_en',\n",
    "       'is_location_unknown', 'creation_hour', 'creation_day_of_week',\n",
    "       'creation_month', 'creation_year', 'is_weekend', 'creation_quarter',\n",
    "       'part_of_day', 'creation_week_of_year', 'is_beginning_of_month',\n",
    "       'is_end_of_month', 'description_length', 'influencer_type',\n",
    "       'favourites_per_day', 'favourites_activity',\n",
    "       'mention_count', 'log_favourites_count', 'log_followers_count', 'log_friends_count',\n",
    "       'log_statuses_count', 'log_average_tweets_per_day',\n",
    "       'log_fol_to_friends_ratio', 'log_fol_to_tweets_ratio',\n",
    "       'log_friends_to_tweets_ratio', 'sentiment_label', 'account_type']\n",
    "\n",
    "features = [col for col in predictive_cols_log if col not in ['id', 'account_type', 'X_fold']]\n",
    "target = ['account_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembling Method for Model Combination\n",
    "\n",
    "The ensembling method aims to combine multiple predictive models, specifically traditional models (XGBoost, LightGBM, and optionally RandomForest) and a neural network model, to improve performance. The ensemble strategy involves weighted averaging of the predictions from the traditional models and the neural network model. Below is a summary of the approach:\n",
    "\n",
    "1. **Model Pairing**:\n",
    "   - The ensemble combines two types of models: traditional machine learning models (XGBoost, LightGBM, etc.) and a neural network model. These models are paired in various combinations for testing.\n",
    "   - In this example, the models used are:\n",
    "     - Random Forest (`modelrf`)\n",
    "     - Neural Network (`modelnn`)\n",
    "\n",
    "2. **Weighting**:\n",
    "   - Different weight combinations are tested for the ensemble predictions. The weights determine how much influence each model's predictions have in the final combined prediction. In the example, the following weight combinations are considered:\n",
    "     - (0.7, 0.3)\n",
    "     - (0.5, 0.5)\n",
    "     - (0.3, 0.7)\n",
    "   - `w1` and `w2` correspond to the weights assigned to the traditional model predictions and neural network predictions, respectively.\n",
    "\n",
    "3. **Prediction Process**:\n",
    "   - For neural network predictions, the model outputs probabilities (for binary classification) that are used in the ensemble.\n",
    "\n",
    "4. **Ensemble Calculation**:\n",
    "   - The predictions from the traditional model (`preds`) and the neural network (`nn_preds`) are combined using the weighted average formula:\n",
    "     \\[\n",
    "     $\\text{ensemble\\_preds} = (w1 \\times \\text{preds}) + (w2 \\times \\text{nn\\_preds})$\n",
    "     \\]\n",
    "   - The combined prediction is then thresholded (at 0.5) to convert probabilities into binary labels (0 or 1).\n",
    "\n",
    "5. **Metrics**:\n",
    "   - The performance of the ensemble is evaluated using several classification metrics:\n",
    "     - **Accuracy**: The proportion of correct predictions.\n",
    "     - **AUC (Area Under the Curve)**: A measure of the model's ability to distinguish between the classes.\n",
    "     - **Recall**: The proportion of actual positives correctly identified by the model.\n",
    "     - **Precision**: The proportion of predicted positives that are actually correct.\n",
    "     - **F1-Score**: The harmonic mean of precision and recall.\n",
    "\n",
    "6. **Best Model and Weight Combination**:\n",
    "   - After testing all combinations, the best model and weight combination is selected based on the highest F1-Score. This combination is considered the most balanced, ensuring both high precision and recall.\n",
    "\n",
    "7. **Output**:\n",
    "   - The model, weight combination, and corresponding metrics (Accuracy, AUC, Recall, Precision, F1-Score) are printed for each iteration.\n",
    "   - Finally, the best model and weight combination are displayed, showing the highest performance across the evaluated metrics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model (RandomForest) with Weight (0.7, 0.3): Accuracy = 0.8690301787283914, AUC = 0.8994477489182051, Recall = 0.7073286052009456, Precision = 0.84472049689441, F1-Score = 0.7699433865156974\n",
      "Model (RandomForest) with Weight (0.5, 0.5): Accuracy = 0.8671256958687372, AUC = 0.8994179409088834, Recall = 0.6940898345153664, Precision = 0.8495370370370371, F1-Score = 0.7639864689045017\n",
      "Model (RandomForest) with Weight (0.3, 0.7): Accuracy = 0.8584822736595371, AUC = 0.8975971432485612, Recall = 0.6628841607565011, Precision = 0.8471299093655589, F1-Score = 0.7437665782493369\n",
      "\n",
      "Best model and weight combination and metrics:\n",
      "Model: RandomForest\n",
      "Weight: (0.7, 0.3)\n",
      "Accuracy: 0.8690301787283914\n",
      "AUC: 0.8994477489182051\n",
      "Recall: 0.7073286052009456\n",
      "Precision: 0.84472049689441\n",
      "F1-Score: 0.7699433865156974\n"
     ]
    }
   ],
   "source": [
    "# Define weight combinations and model pairs\n",
    "weights = [(0.7, 0.3), (0.5, 0.5), (0.3, 0.7)]\n",
    "model_pairs = [('RandomForest', modelrf)]\n",
    "\n",
    "nn_model = modelnn  # Neural network model instance\n",
    "\n",
    "# Prepare data\n",
    "X = mds[features]\n",
    "y = mds[target]\n",
    "# Convert X to a tensor for NN model\n",
    "X_tensor = torch.tensor(X.values, dtype=torch.float32)  \n",
    "\n",
    "# Get predictions from the neural network model\n",
    "with torch.no_grad():\n",
    "    nn_outputs = nn_model(X_tensor).numpy() \n",
    "    nn_preds = nn_outputs[:, 1]  \n",
    "\n",
    "# Initialize variables to track the best combination and metrics\n",
    "best_combination = None\n",
    "best_metrics = {}\n",
    "\n",
    "# Iterate through each model pair\n",
    "for model_name, model in model_pairs:\n",
    "    try:\n",
    "            preds = cross_val_predict(model, X, y, cv=3, method='predict_proba')[:, 1]\n",
    "    except IndexError:\n",
    "            preds = cross_val_predict(model, X, y, cv=3, method='predict')\n",
    "\n",
    "    # Iterate through each weight combination\n",
    "    for w1, w2 in weights:\n",
    "        # Weighted averaging of probabilities\n",
    "        ensemble_preds = (w1 * preds + w2 * nn_preds)\n",
    "        binary_preds = (ensemble_preds >= 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y, binary_preds)\n",
    "        auc = roc_auc_score(y, ensemble_preds) if 'predict_proba' in dir(model) else None\n",
    "        recall = recall_score(y, binary_preds)\n",
    "        precision = precision_score(y, binary_preds)\n",
    "        f1 = f1_score(y, binary_preds)\n",
    "        \n",
    "        print(f\"Model ({model_name}) with Weight ({w1}, {w2}): Accuracy = {accuracy}, AUC = {auc}, Recall = {recall}, Precision = {precision}, F1-Score = {f1}\")\n",
    "        \n",
    "        # Update best metrics based on F1-score\n",
    "        if not best_metrics or f1 > best_metrics['f1']:\n",
    "            best_metrics = {\n",
    "                'model': model_name,\n",
    "                'weight': (w1, w2),\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'recall': recall,\n",
    "                'precision': precision,\n",
    "                'f1': f1\n",
    "            }\n",
    "\n",
    "print(\"\\nBest model and weight combination and metrics:\")\n",
    "print(f\"Model: {best_metrics['model']}\")\n",
    "print(f\"Weight: {best_metrics['weight']}\")\n",
    "print(f\"Accuracy: {best_metrics['accuracy']}\")\n",
    "print(f\"AUC: {best_metrics['auc']}\")\n",
    "print(f\"Recall: {best_metrics['recall']}\")\n",
    "print(f\"Precision: {best_metrics['precision']}\")\n",
    "print(f\"F1-Score: {best_metrics['f1']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
