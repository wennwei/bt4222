{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df = pd.read_csv(\"source data/twitter_human_bots_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'created_at' to datetime\n",
    "df['created_at'] = pd.to_datetime(df['created_at'], errors='coerce')\n",
    "\n",
    "# Calculate Account Age\n",
    "current_time = datetime.now()\n",
    "df['account_age_days'] = (current_time - df['created_at']).dt.days\n",
    "\n",
    "# Time-Based Features\n",
    "df['creation_hour'] = df['created_at'].dt.hour\n",
    "df['creation_day_of_week'] = df['created_at'].dt.dayofweek\n",
    "df['creation_month'] = df['created_at'].dt.month\n",
    "df['creation_year'] = df['created_at'].dt.year\n",
    "df['creation_quarter'] = df['created_at'].dt.quarter\n",
    "df['is_weekend'] = df['creation_day_of_week'] >= 5\n",
    "df['creation_week_of_year'] = df['created_at'].dt.isocalendar().week\n",
    "df['is_beginning_of_month'] = df['created_at'].dt.day <= 5\n",
    "df['is_end_of_month'] = df['created_at'].dt.day >= 26\n",
    "\n",
    "# Define part of day based on hour\n",
    "def part_of_day(hour):\n",
    "    if 5 <= hour < 12:\n",
    "        return 'Morning'\n",
    "    elif 12 <= hour < 17:\n",
    "        return 'Afternoon'\n",
    "    elif 17 <= hour < 21:\n",
    "        return 'Evening'\n",
    "    else:\n",
    "        return 'Night'\n",
    "\n",
    "df['part_of_day'] = df['creation_hour'].apply(part_of_day)\n",
    "\n",
    "# Additional Features\n",
    "humans_mean = df[df['account_type'] == 'human']['average_tweets_per_day'].mean()\n",
    "humans_std = df[df['account_type'] == 'human']['average_tweets_per_day'].std()\n",
    "df['deviation_from_humans'] = (df['average_tweets_per_day'] - humans_mean) / humans_std\n",
    "\n",
    "# Description Length Feature\n",
    "df['description_length'] = df['description'].apply(lambda x: len(str(x)) if pd.notnull(x) else 0)\n",
    "\n",
    "# Followers/Friends Ratios\n",
    "df['followers_to_friends_ratio'] = df['followers_count'] / df['friends_count']\n",
    "df['followers_to_friends_ratio'].fillna(0, inplace=True)\n",
    "\n",
    "# Followers to Tweets Per Day Ratio\n",
    "df['followers_to_tweets_per_day_ratio'] = df['followers_count'] / df['average_tweets_per_day']\n",
    "df['followers_to_tweets_per_day_ratio'].fillna(0, inplace=True)\n",
    "\n",
    "# Mentions Count in Description\n",
    "import re\n",
    "\n",
    "def extract_mentions(description):\n",
    "    return re.findall(r'@\\w+', str(description))\n",
    "\n",
    "df['mentions'] = df['description'].apply(extract_mentions)\n",
    "df['mention_count'] = df['mentions'].apply(len)\n",
    "\n",
    "# Ensure any remaining NaN values are filled if necessary\n",
    "########################################################################\n",
    "# TO DISCUSS METHOD OF IMPUTATION\n",
    "########################################################################\n",
    "df.fillna(0, inplace=True)\n",
    "df.replace(np.inf,0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Unnamed: 0                     created_at  default_profile  \\\n",
      "count  37438.000000                          37438     37438.000000   \n",
      "mean   18718.500000  2012-05-10 19:06:11.558710528         0.419894   \n",
      "min        0.000000            2006-07-05 19:52:46         0.000000   \n",
      "25%     9359.250000  2009-12-26 20:54:38.750000128         0.000000   \n",
      "50%    18718.500000            2011-10-27 02:04:41         0.000000   \n",
      "75%    28077.750000            2014-04-16 15:39:40         1.000000   \n",
      "max    37437.000000            2019-04-24 08:53:21         1.000000   \n",
      "std    10807.564026                            NaN         0.493548   \n",
      "\n",
      "       default_profile_image  favourites_count  followers_count  \\\n",
      "count           37438.000000      37438.000000     3.743800e+04   \n",
      "mean                0.014905      12302.062183     3.703098e+05   \n",
      "min                 0.000000          0.000000     0.000000e+00   \n",
      "25%                 0.000000        362.000000     3.500000e+01   \n",
      "50%                 0.000000       2066.000000     3.650000e+02   \n",
      "75%                 0.000000       8879.000000     8.440250e+03   \n",
      "max                 1.000000     885123.000000     1.216415e+08   \n",
      "std                 0.121173      33923.650237     2.470829e+06   \n",
      "\n",
      "       friends_count   geo_enabled            id          lang  ...  \\\n",
      "count   3.743800e+04  37438.000000  3.743800e+04  37438.000000  ...   \n",
      "mean    4.445925e+03      0.456141  1.221536e+17      9.959800  ...   \n",
      "min     0.000000e+00      0.000000  4.180000e+02      0.000000  ...   \n",
      "25%     3.700000e+01      0.000000  9.957306e+07      7.000000  ...   \n",
      "50%     2.960000e+02      0.000000  3.991474e+08     10.000000  ...   \n",
      "75%     8.930000e+02      1.000000  2.453826e+09     10.000000  ...   \n",
      "max     4.343060e+06      1.000000  1.120974e+18     48.000000  ...   \n",
      "std     4.954520e+04      0.498079  3.004313e+17      8.821715  ...   \n",
      "\n",
      "         is_weekend  creation_week_of_year  is_beginning_of_month  \\\n",
      "count  37438.000000                37438.0           37438.000000   \n",
      "mean       0.252337              25.293392               0.175570   \n",
      "min        0.000000                    1.0               0.000000   \n",
      "25%        0.000000                   13.0               0.000000   \n",
      "50%        0.000000                   25.0               0.000000   \n",
      "75%        1.000000                   37.0               0.000000   \n",
      "max        1.000000                   53.0               1.000000   \n",
      "std        0.434360              14.539285               0.380459   \n",
      "\n",
      "       is_end_of_month   part_of_day  deviation_from_humans  \\\n",
      "count     37438.000000  37438.000000           37438.000000   \n",
      "mean          0.172018      1.737593               0.012280   \n",
      "min           0.000000      0.000000              -0.460227   \n",
      "25%           0.000000      1.000000              -0.426289   \n",
      "50%           0.000000      2.000000              -0.358206   \n",
      "75%           0.000000      3.000000              -0.081216   \n",
      "max           1.000000      3.000000              86.548835   \n",
      "std           0.377401      1.175178               1.685264   \n",
      "\n",
      "       description_length  followers_to_friends_ratio  \\\n",
      "count        37438.000000                3.743800e+04   \n",
      "mean            67.017202                9.123033e+03   \n",
      "min              0.000000                0.000000e+00   \n",
      "25%             14.000000                1.548705e-01   \n",
      "50%             58.000000                8.281594e-01   \n",
      "75%            118.000000                5.987312e+00   \n",
      "max            191.000000                5.547370e+07   \n",
      "std             55.217549                3.898016e+05   \n",
      "\n",
      "       followers_to_tweets_per_day_ratio  mention_count  \n",
      "count                       3.743800e+04   37438.000000  \n",
      "mean                        9.329537e+05       0.299135  \n",
      "min                         0.000000e+00       0.000000  \n",
      "25%                         4.602353e+01       0.000000  \n",
      "50%                         2.146013e+02       0.000000  \n",
      "75%                         2.729065e+03       0.000000  \n",
      "max                         7.379663e+09      12.000000  \n",
      "std                         5.338276e+07       0.849194  \n",
      "\n",
      "[8 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Encoding Categorical Features\n",
    "df['account_type'] = df['account_type'].map({'human': 0, 'bot': 1})\n",
    "\n",
    "encode_cols = ['default_profile', 'default_profile_image', 'geo_enabled', 'lang', 'location', 'verified',\n",
    "               'creation_year', 'is_weekend', 'is_beginning_of_month', 'is_end_of_month', 'part_of_day']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for col in encode_cols:\n",
    "    df[col] = label_encoder.fit_transform(df[col].astype(str))  # Convert to string to handle NaNs if any\n",
    "\n",
    "\n",
    "# Define Feature Columns and Target\n",
    "id_col = ['id']\n",
    "labels = ['account_type']\n",
    "predictive_cols = ['default_profile', 'default_profile_image', 'favourites_count', 'followers_count', 'friends_count',\n",
    "                   'geo_enabled', 'lang', 'location', 'statuses_count', 'verified', 'average_tweets_per_day', \n",
    "                   'account_age_days', 'creation_hour', 'creation_day_of_week', 'creation_month', 'creation_year',\n",
    "                   'creation_quarter', 'is_weekend', 'creation_week_of_year', 'is_beginning_of_month', \n",
    "                   'is_end_of_month', 'part_of_day', 'deviation_from_humans', 'description_length', \n",
    "                   'followers_to_friends_ratio', 'followers_to_tweets_per_day_ratio', 'mention_count','account_type']\n",
    "\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenize \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def process_text(text):\n",
    "    # Check if the input is not a string, return an empty string if so\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Replace links with {link} and videos with [video]\n",
    "    text = re.sub(r'{link}', '', text)\n",
    "    text = re.sub(r\"\\[video\\]\", '', text)\n",
    "    \n",
    "    # Convert to Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    return text\n",
    "\n",
    "# Process text\n",
    "texts = df['description'].apply(lambda x: process_text(x))\n",
    "\n",
    "vocab_size = 14225  # You can adjust this based on your dataset size and memory limits\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "# Tokenize text\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "# 4. Pad sequences to ensure they all have the same length\n",
    "max_length = 50  # Adjust based on typical length of descriptions in your dataset\n",
    "data = pad_sequences(sequences, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split text and numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['account_type']\n",
    "x_text = data\n",
    "# removed target and description columns, and a few other text columns\n",
    "x_num = df.drop(columns=[\n",
    "    'description', 'account_type',\n",
    "    'created_at', 'profile_background_image_url', 'profile_image_url', 'screen_name', 'mentions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate into train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_text_train, x_text_test, x_num_train, x_num_test, y_train, y_test = train_test_split(\n",
    "    x_text, x_num, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TwitterDataset(Dataset):\n",
    "    def __init__(self, text_data, num_data, labels):\n",
    "        self.text_data = torch.tensor(text_data, dtype=torch.long)  # Text as long integers\n",
    "        self.num_data = torch.tensor(num_data.astype('float32').values, dtype=torch.float32)  # Numerical features as float\n",
    "        self.labels = torch.tensor(labels.values, dtype=torch.long)  # Labels as long (for classification)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'text': self.text_data[idx],\n",
    "            'numerical': self.num_data[idx],\n",
    "            'label': self.labels[idx]\n",
    "        }\n",
    "    \n",
    "# Initialize Dataset and DataLoader\n",
    "train_dataset = TwitterDataset(x_text_train, x_num_train, y_train)\n",
    "test_dataset = TwitterDataset(x_text_test, x_num_test, y_test)\n",
    "\n",
    "# # Define DataLoader for train and test sets\n",
    "batch_size = 512 # 512\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class TwitterBotDetector(nn.Module):\n",
    "    def __init__(self, num_numerical_features, embedding_dim, hidden_dim):\n",
    "        super(TwitterBotDetector, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "        self.fc1 = nn.Linear(embedding_dim + num_numerical_features, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)  # Output layer for binary classification\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x_text, x_num):\n",
    "        x_embed = self.embedding(x_text)\n",
    "        x_embed = x_embed.mean(dim=1)  # Average embeddings over the sequence\n",
    "        x = torch.cat((x_embed, x_num), dim=1)  # Concatenate text and numerical features\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return self.sigmoid(x)  # Sigmoid for binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 35.4331\n",
      "Epoch [2/5], Loss: 30.3150\n",
      "Epoch [3/5], Loss: 37.4016\n",
      "Epoch [4/5], Loss: 29.1339\n",
      "Epoch [5/5], Loss: 37.4016\n"
     ]
    }
   ],
   "source": [
    "model = TwitterBotDetector(num_numerical_features=x_num.shape[1], \n",
    "                           embedding_dim=50, \n",
    "                           hidden_dim=128)\n",
    "\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy Loss for binary classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    for batch in train_loader:\n",
    "        text_batch = batch['text']  # Access text data\n",
    "        num_batch = batch['numerical']  # Access numerical data\n",
    "        labels = batch['label']  # Access labels\n",
    "\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = model(text_batch, num_batch)  # Forward pass\n",
    "        loss = criterion(outputs, labels.float().view(-1, 1))  # Calculate loss\n",
    "        \n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6679\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for batch in test_loader:\n",
    "        text_batch = batch['text']  # Access text data\n",
    "        num_batch = batch['numerical']  # Access numerical data\n",
    "        labels = batch['label']  # Access labels\n",
    "\n",
    "        outputs = model(text_batch, num_batch)\n",
    "        predicted = (outputs > 0.5).float()  # Thresholding to get predictions\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted.view(-1) == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'Accuracy: {accuracy:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
