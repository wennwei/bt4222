{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "### Tree based models\n",
    "* XGB, LGBM, RF, ETC, DT\n",
    "\n",
    "### Neural Networks\n",
    "* NN, autoencoders(?), GNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Shap for model explanability both local and global\n",
    "* Tune model on best model selected (either on precision/f1/recall and feature blend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model on out of sample set\n",
    "* Get metrics(acc,precision,f1, etc..) from out of sample set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dashboard(?) --enhancement\n",
    "* Transfer results to a dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import file here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df = pd.read_csv(\"twitter_human_bots_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert 'created_at' to datetime\n",
    "df['created_at'] = pd.to_datetime(df['created_at'], errors='coerce')\n",
    "\n",
    "# Calculate Account Age\n",
    "current_time = datetime.now()\n",
    "df['account_age_days'] = (current_time - df['created_at']).dt.days\n",
    "\n",
    "# Time-Based Features\n",
    "df['creation_hour'] = df['created_at'].dt.hour\n",
    "df['creation_day_of_week'] = df['created_at'].dt.dayofweek\n",
    "df['creation_month'] = df['created_at'].dt.month\n",
    "df['creation_year'] = df['created_at'].dt.year\n",
    "df['creation_quarter'] = df['created_at'].dt.quarter\n",
    "df['is_weekend'] = df['creation_day_of_week'] >= 5\n",
    "df['creation_week_of_year'] = df['created_at'].dt.isocalendar().week\n",
    "df['is_beginning_of_month'] = df['created_at'].dt.day <= 5\n",
    "df['is_end_of_month'] = df['created_at'].dt.day >= 26\n",
    "\n",
    "# Define part of day based on hour\n",
    "def part_of_day(hour):\n",
    "    if 5 <= hour < 12:\n",
    "        return 'Morning'\n",
    "    elif 12 <= hour < 17:\n",
    "        return 'Afternoon'\n",
    "    elif 17 <= hour < 21:\n",
    "        return 'Evening'\n",
    "    else:\n",
    "        return 'Night'\n",
    "\n",
    "df['part_of_day'] = df['creation_hour'].apply(part_of_day)\n",
    "\n",
    "# Additional Features\n",
    "humans_mean = df[df['account_type'] == 'human']['average_tweets_per_day'].mean()\n",
    "humans_std = df[df['account_type'] == 'human']['average_tweets_per_day'].std()\n",
    "df['deviation_from_humans'] = (df['average_tweets_per_day'] - humans_mean) / humans_std\n",
    "\n",
    "# Description Length Feature\n",
    "df['description_length'] = df['description'].apply(lambda x: len(str(x)) if pd.notnull(x) else 0)\n",
    "\n",
    "# Followers/Friends Ratios\n",
    "df['followers_to_friends_ratio'] = df['followers_count'] / df['friends_count']\n",
    "df['followers_to_friends_ratio'].fillna(0, inplace=True)\n",
    "\n",
    "# Followers to Tweets Per Day Ratio\n",
    "df['followers_to_tweets_per_day_ratio'] = df['followers_count'] / df['average_tweets_per_day']\n",
    "df['followers_to_tweets_per_day_ratio'].fillna(0, inplace=True)\n",
    "\n",
    "# Mentions Count in Description\n",
    "import re\n",
    "\n",
    "def extract_mentions(description):\n",
    "    return re.findall(r'@\\w+', str(description))\n",
    "\n",
    "df['mentions'] = df['description'].apply(extract_mentions)\n",
    "df['mention_count'] = df['mentions'].apply(len)\n",
    "\n",
    "# Ensure any remaining NaN values are filled if necessary\n",
    "########################################################################\n",
    "# TO DISCUSS METHOD OF IMPUTATION\n",
    "########################################################################\n",
    "df.fillna(0, inplace=True)\n",
    "df.replace(np.inf,0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENCODING METHOD FOR LANG AND LOCATION TO BE DISCUSSSED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding Categorical Features\n",
    "df['account_type'] = df['account_type'].map({'human': 0, 'bot': 1})\n",
    "\n",
    "encode_cols = ['default_profile', 'default_profile_image', 'geo_enabled', 'lang', 'location', 'verified',\n",
    "               'creation_year', 'is_weekend', 'is_beginning_of_month', 'is_end_of_month', 'part_of_day']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for col in encode_cols:\n",
    "    df[col] = label_encoder.fit_transform(df[col].astype(str))  # Convert to string to handle NaNs if any\n",
    "\n",
    "\n",
    "# Define Feature Columns and Target\n",
    "id_col = ['id']\n",
    "labels = ['account_type']\n",
    "predictive_cols = ['default_profile', 'default_profile_image', 'favourites_count', 'followers_count', 'friends_count',\n",
    "                   'geo_enabled', 'lang', 'location', 'statuses_count', 'verified', 'average_tweets_per_day', \n",
    "                   'account_age_days', 'creation_hour', 'creation_day_of_week', 'creation_month', 'creation_year',\n",
    "                   'creation_quarter', 'is_weekend', 'creation_week_of_year', 'is_beginning_of_month', \n",
    "                   'is_end_of_month', 'part_of_day', 'deviation_from_humans', 'description_length', \n",
    "                   'followers_to_friends_ratio', 'followers_to_tweets_per_day_ratio', 'mention_count','account_type']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set cutoff date for training/validation split\n",
    "cutoff_date = pd.to_datetime('2017-01-01')\n",
    "df['date'] = pd.to_datetime(df['created_at'])\n",
    "\n",
    "# Define columns to keep\n",
    "id_cols = ['id']\n",
    "target_cols = ['account_type']\n",
    "# Assuming predictive_cols is already defined\n",
    "columns_to_keep = id_cols + predictive_cols\n",
    "\n",
    "# Filter columns before splitting\n",
    "df_filtered = df[columns_to_keep + ['date']]\n",
    "\n",
    "# Split data based on cutoff date\n",
    "oot = df_filtered[df_filtered['date'] >= cutoff_date].set_index('id')\n",
    "df_model = df_filtered[df_filtered['date'] < cutoff_date].set_index('id')\n",
    "\n",
    "# Drop date column as it's no longer needed\n",
    "oot = oot.drop('date', axis=1)\n",
    "df_model = df_model.drop('date', axis=1)\n",
    "\n",
    "# Train, Test, Validation Splits\n",
    "RANDOM_SEED = 2024\n",
    "train, test = train_test_split(df_model, test_size=0.2, random_state=RANDOM_SEED)\n",
    "train, valid = train_test_split(train, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "# Add 'X_fold' columns for each split\n",
    "train['X_fold'] = 'train'\n",
    "test['X_fold'] = 'test'\n",
    "valid['X_fold'] = 'valid'\n",
    "oot['X_fold'] = 'oot'\n",
    "\n",
    "# Combine all datasets for modeling\n",
    "mds = pd.concat([train, test, valid, oot]).copy(deep=True)\n",
    "mds = mds.reset_index()\n",
    "\n",
    "# Plot correlation heatmap for predictive columns\n",
    "corr = mds[predictive_cols].corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Heatmap of Predictive Features')\n",
    "plt.show()\n",
    "\n",
    "# Check target distribution\n",
    "print(\"\\nTarget Distribution:\")\n",
    "print(mds['account_type'].value_counts())\n",
    "print(\"\\nTarget Distribution (%):\")\n",
    "print(mds['account_type'].value_counts(normalize=True) * 100)\n",
    "\n",
    "# Final Data Overview\n",
    "print(\"\\nData Sample:\")\n",
    "print(mds.head())\n",
    "print(\"\\nDataset Info:\")\n",
    "print(mds.info())\n",
    "\n",
    "# Verify final columns\n",
    "print(\"\\nFinal columns in dataset:\")\n",
    "print(mds.columns.tolist())\n",
    "\n",
    "# Verify data splits\n",
    "print(\"\\nData split sizes:\")\n",
    "print(mds['X_fold'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "from hyperopt import hp\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import custom functions\n",
    "# from utils import mpr_report, final_fitting\n",
    "\n",
    "# from lmf2 import LoadModelFunction#, final_fitting\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Might shift this into another file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from xgboost import DMatrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.model_selection import KFold, TimeSeriesSplit\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import time\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import json\n",
    "from functools import partial\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class UnifiedModelTrainer:\n",
    "    def __init__(self, random_state=2024):\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def prepare_data(self, df, features, target):\n",
    "        \"\"\"Prepare train, validation, test and out-of-time datasets\"\"\"\n",
    "        train_valid = df[df['X_fold'].isin(['train', 'valid'])]\n",
    "        test = df[df['X_fold'] == 'test']\n",
    "        oot = df[df['X_fold'] == 'oot']\n",
    "        \n",
    "        X_train_valid = train_valid[features]\n",
    "        y_train_valid = train_valid[target]\n",
    "        \n",
    "        X_test = test[features]\n",
    "        y_test = test[target]\n",
    "        \n",
    "        X_oot = oot[features]\n",
    "        y_oot = oot[target]\n",
    "        \n",
    "        return (X_train_valid, y_train_valid), (X_test, y_test), (X_oot, y_oot)\n",
    "    \n",
    "    def evaluate_model(self, model, X_test, y_test, X_oot, y_oot):\n",
    "        \"\"\"Evaluate model performance on test and OOT datasets\"\"\"\n",
    "        if isinstance(model, lgb.Booster):\n",
    "            pred_test = model.predict(X_test)\n",
    "            pred_oot = model.predict(X_oot)\n",
    "        else:\n",
    "            pred_test = model.predict_proba(X_test)[:, 1]\n",
    "            pred_oot = model.predict_proba(X_oot)[:, 1]\n",
    "        \n",
    "        metrics = {\n",
    "            'test_auc': roc_auc_score(y_test, pred_test),\n",
    "            'oot_auc': roc_auc_score(y_oot, pred_oot)\n",
    "        }\n",
    "        \n",
    "        # Calculate additional metrics for different thresholds\n",
    "        threshold_metrics = {}\n",
    "        for threshold in [0.5, 0.8, 0.85, 0.9, 0.95]:\n",
    "            pred_test_binary = (pred_test > threshold).astype(int)\n",
    "            pred_oot_binary = (pred_oot > threshold).astype(int)\n",
    "            \n",
    "            threshold_metrics[f'threshold_{threshold}'] = {\n",
    "                'test': {\n",
    "                    'precision': precision_score(y_test, pred_test_binary),\n",
    "                    'recall': recall_score(y_test, pred_test_binary),\n",
    "                    'f1': f1_score(y_test, pred_test_binary),\n",
    "                    'auc': roc_auc_score(y_test, pred_test_binary)\n",
    "                },\n",
    "                'oot': {\n",
    "                    'precision': precision_score(y_oot, pred_oot_binary),\n",
    "                    'recall': recall_score(y_oot, pred_oot_binary),\n",
    "                    'f1': f1_score(y_oot, pred_oot_binary),\n",
    "                    'auc': roc_auc_score(y_oot, pred_oot_binary)\n",
    "\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        metrics['threshold_metrics'] = threshold_metrics\n",
    "        return metrics\n",
    "        \n",
    "    from hyperopt import hp\n",
    "\n",
    "    def create_search_space(self, model_type):\n",
    "        \"\"\"Define complete search space including data preparation and model parameters.\"\"\"\n",
    "        \n",
    "        # Common parameters\n",
    "        common_params = {\n",
    "            'k_folds': hp.choice('k_folds', [3, 5, 7, 10]),\n",
    "            'k_split': hp.choice('k_split', ['non_ts', 'ts']),\n",
    "            \n",
    "            # Feature selection parameters\n",
    "            'f_method': hp.choice('f_method', [\n",
    "                'all',  # Use all features\n",
    "                'kbest_f',  # SelectKBest with f_classif\n",
    "                'kbest_mi',  # SelectKBest with mutual_info_classif\n",
    "                'l1',  # L1-based feature selection\n",
    "                'tree_importance'  # Tree-based feature importance\n",
    "            ]),\n",
    "            'num_feats': hp.choice('num_feats', [20, 30, 40, 50, 'all']),\n",
    "            \n",
    "            # Scaling parameters\n",
    "            'scaler': hp.choice('scaler', [\n",
    "                'noscaler',\n",
    "                'standard',\n",
    "                'minmax',\n",
    "                'robust'\n",
    "            ]),\n",
    "            \n",
    "            # Fixed parameters\n",
    "            'SEED': self.random_state\n",
    "        }\n",
    "        \n",
    "        if model_type == 'lgbm':\n",
    "            # LightGBM specific parameters\n",
    "            lgbm_params = {\n",
    "                'num_leaves': hp.quniform('num_leaves', 15, 127, 1),\n",
    "                'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "                'feature_fraction': hp.uniform('feature_fraction', 0.6, 0.9),\n",
    "                'bagging_fraction': hp.uniform('bagging_fraction', 0.6, 0.9),\n",
    "                'bagging_freq': hp.quniform('bagging_freq', 2, 10, 1),\n",
    "                'min_child_samples': hp.quniform('min_child_samples', 10, 150, 1),\n",
    "                'max_depth': hp.quniform('max_depth', 3, 12, 1),\n",
    "                'n_estimators': hp.quniform('n_estimators', 100, 1000, 50)\n",
    "            }\n",
    "            return {**common_params, **lgbm_params}\n",
    "\n",
    "        elif model_type == 'xgb':\n",
    "            # XGBoost specific parameters\n",
    "            xgb_params = {\n",
    "                'max_depth': hp.quniform('max_depth', 3, 12, 1),\n",
    "                'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "                'subsample': hp.uniform('subsample', 0.6, 1.0),\n",
    "                'colsample_bytree': hp.uniform('colsample_bytree', 0.6, 1.0),\n",
    "                'min_child_weight': hp.quniform('min_child_weight', 1, 7, 1),\n",
    "                'n_estimators': hp.quniform('n_estimators', 100, 1000, 50)\n",
    "            }\n",
    "            return {**common_params, **xgb_params}\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"Invalid model type. Please choose 'lgbm' or 'xgb'.\")\n",
    "\n",
    "    \n",
    "    def apply_feature_selection(self, X, y, method, num_feats):\n",
    "        \"\"\"Apply feature selection based on specified method\"\"\"\n",
    "        if method == 'all' or num_feats == 'all':\n",
    "            return X\n",
    "            \n",
    "        n_features = min(num_feats, X.shape[1])\n",
    "        \n",
    "        if method == 'kbest_f':\n",
    "            selector = SelectKBest(score_func=f_classif, k=n_features)\n",
    "        elif method == 'kbest_mi':\n",
    "            selector = SelectKBest(score_func=mutual_info_classif, k=n_features)\n",
    "        elif method == 'l1':\n",
    "            from sklearn.linear_model import LogisticRegression\n",
    "            selector = LogisticRegression(penalty='l1', solver='saga', random_state=self.random_state)\n",
    "            selector.fit(X, y)\n",
    "            mask = np.abs(selector.coef_[0]) > 0\n",
    "            return X.iloc[:, mask]\n",
    "        elif method == 'tree_importance':\n",
    "            model = lgb.LGBMClassifier(random_state=self.random_state)\n",
    "            model.fit(X, y)\n",
    "            importance = pd.Series(model.feature_importances_, index=X.columns)\n",
    "            selected_features = importance.nlargest(n_features).index\n",
    "            return X[selected_features]\n",
    "            \n",
    "        if method in ['kbest_f', 'kbest_mi']:\n",
    "            selector.fit(X, y)\n",
    "            mask = selector.get_support()\n",
    "            return X.iloc[:, mask]\n",
    "            \n",
    "        return X\n",
    "    \n",
    "    def plot_results(self, metrics, output_dir):\n",
    "        \"\"\"Create and save visualization of results\"\"\"\n",
    "        # Plot threshold performance\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        thresholds = sorted(metrics['threshold_metrics'].keys(), \n",
    "                          key=lambda x: float(x.split('_')[1]))\n",
    "        \n",
    "        test_precision = [metrics['threshold_metrics'][t]['test']['precision'] \n",
    "                         for t in thresholds]\n",
    "        oot_precision = [metrics['threshold_metrics'][t]['oot']['precision'] \n",
    "                        for t in thresholds]\n",
    "        \n",
    "        plt.plot(thresholds, test_precision, label='Test Precision')\n",
    "        plt.plot(thresholds, oot_precision, label='OOT Precision')\n",
    "        plt.xlabel('Threshold')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('Model Performance Across Thresholds')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{output_dir}/threshold_performance.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def apply_scaling(self, X_train, X_test, X_oot, scaler_type):\n",
    "        \"\"\"Apply scaling transformation to the data\"\"\"\n",
    "        if scaler_type == 'noscaler':\n",
    "            return X_train, X_test, X_oot\n",
    "            \n",
    "        if scaler_type == 'standard':\n",
    "            scaler = StandardScaler()\n",
    "        elif scaler_type == 'minmax':\n",
    "            scaler = MinMaxScaler()\n",
    "        elif scaler_type == 'robust':\n",
    "            scaler = RobustScaler()\n",
    "            \n",
    "        X_train_scaled = pd.DataFrame(\n",
    "            scaler.fit_transform(X_train),\n",
    "            columns=X_train.columns,\n",
    "            index=X_train.index\n",
    "        )\n",
    "        X_test_scaled = pd.DataFrame(\n",
    "            scaler.transform(X_test),\n",
    "            columns=X_test.columns,\n",
    "            index=X_test.index\n",
    "        )\n",
    "        X_oot_scaled = pd.DataFrame(\n",
    "            scaler.transform(X_oot),\n",
    "            columns=X_oot.columns,\n",
    "            index=X_oot.index\n",
    "        )\n",
    "        \n",
    "        return X_train_scaled, X_test_scaled, X_oot_scaled\n",
    "    \n",
    "    def get_cv_splitter(self, k_split, k_folds):\n",
    "        \"\"\"Get cross-validation splitter based on specified method\"\"\"\n",
    "        if k_split == 'non_ts':\n",
    "            return KFold(n_splits=k_folds, shuffle=True, random_state=self.random_state)\n",
    "        else:\n",
    "            return TimeSeriesSplit(n_splits=k_folds)\n",
    "    \n",
    "    def objective_lgb(self, space, X_train, y_train, X_test, y_test, X_oot, y_oot):\n",
    "        \"\"\"Enhanced objective function for LightGBM optimization\"\"\"\n",
    "        try:\n",
    "            # Apply feature selection\n",
    "            X_train_selected = self.apply_feature_selection(\n",
    "                X_train, y_train, space['f_method'], space['num_feats']\n",
    "            )\n",
    "            X_test_selected = X_test[X_train_selected.columns]\n",
    "            X_oot_selected = X_oot[X_train_selected.columns]\n",
    "            \n",
    "            # Apply scaling\n",
    "            X_train_processed, X_test_processed, X_oot_processed = self.apply_scaling(\n",
    "                X_train_selected, X_test_selected, X_oot_selected, space['scaler']\n",
    "            )\n",
    "            \n",
    "            # Create CV splitter\n",
    "            cv_splitter = self.get_cv_splitter(space['k_split'], int(space['k_folds']))\n",
    "            \n",
    "            # Prepare LightGBM parameters\n",
    "            params = {\n",
    "                'objective': 'binary',\n",
    "                'metric': 'auc',\n",
    "                'boosting_type': 'gbdt',\n",
    "                'num_leaves': int(space['num_leaves']),\n",
    "                'learning_rate': space['learning_rate'],\n",
    "                'feature_fraction': space['feature_fraction'],\n",
    "                'bagging_fraction': space['bagging_fraction'],\n",
    "                'bagging_freq': int(space['bagging_freq']),\n",
    "                'min_child_samples': int(space['min_child_samples']),\n",
    "                'max_depth': int(space['max_depth']),\n",
    "                'n_estimators': int(space['n_estimators']),\n",
    "                'verbose': -1,\n",
    "                'random_state': space['SEED']\n",
    "            }\n",
    "            \n",
    "            # Cross-validation scores\n",
    "            cv_scores = []\n",
    "            for train_idx, valid_idx in cv_splitter.split(X_train_processed):\n",
    "                X_fold_train = X_train_processed.iloc[train_idx]\n",
    "                y_fold_train = y_train.iloc[train_idx]\n",
    "                X_fold_valid = X_train_processed.iloc[valid_idx]\n",
    "                y_fold_valid = y_train.iloc[valid_idx]\n",
    "                \n",
    "                train_data = lgb.Dataset(X_fold_train, label=y_fold_train)\n",
    "                valid_data = lgb.Dataset(X_fold_valid, label=y_fold_valid, reference=train_data)\n",
    "                \n",
    "                model = lgb.train(\n",
    "                    params,\n",
    "                    train_data,\n",
    "                    valid_sets=[valid_data],\n",
    "                    callbacks=[lgb.early_stopping(stopping_rounds=20)]\n",
    "                )\n",
    "                \n",
    "                pred_valid = model.predict(X_fold_valid)\n",
    "                cv_scores.append(roc_auc_score(y_fold_valid, pred_valid)) # modify metric here for tuning for other metrics\n",
    "            \n",
    "            # Train final model on full training data\n",
    "            train_data = lgb.Dataset(X_train_processed, label=y_train)\n",
    "            valid_data = lgb.Dataset(X_test_processed, label=y_test, reference=train_data)\n",
    "            \n",
    "            final_model = lgb.train(\n",
    "                params,\n",
    "                train_data,\n",
    "                valid_sets=[valid_data],\n",
    "                callbacks=[lgb.early_stopping(stopping_rounds=20)]\n",
    "            )\n",
    "            \n",
    "            # Calculate metrics\n",
    "            metrics = self.evaluate_model(\n",
    "                final_model, \n",
    "                X_test_processed, y_test,\n",
    "                X_oot_processed, y_oot\n",
    "            )\n",
    "            \n",
    "            metrics['cv_score_mean'] = np.mean(cv_scores)\n",
    "            metrics['cv_score_std'] = np.std(cv_scores)\n",
    "            \n",
    "            return {\n",
    "                'loss': -metrics['cv_score_mean'],  # Optimize for CV performance\n",
    "                'status': STATUS_OK,\n",
    "                'model': final_model,\n",
    "                'metrics': metrics,\n",
    "                'params': params,\n",
    "                'feature_columns': list(X_train_processed.columns)\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in objective function: {str(e)}\")\n",
    "            return {'loss': 0, 'status': STATUS_OK, 'model': None}\n",
    "    \n",
    "    def objective_xgb(self, space, X_train, y_train, X_test, y_test, X_oot, y_oot):\n",
    "        \"\"\"Enhanced objective function for XGBoost optimization\"\"\"\n",
    "        try:\n",
    "            # Apply feature selection\n",
    "            X_train_selected = self.apply_feature_selection(\n",
    "                X_train, y_train, space['f_method'], space['num_feats']\n",
    "            )\n",
    "            X_test_selected = X_test[X_train_selected.columns]\n",
    "            X_oot_selected = X_oot[X_train_selected.columns]\n",
    "            \n",
    "            # Apply scaling\n",
    "            X_train_processed, X_test_processed, X_oot_processed = self.apply_scaling(\n",
    "                X_train_selected, X_test_selected, X_oot_selected, space['scaler']\n",
    "            )\n",
    "            \n",
    "            # Create CV splitter\n",
    "            cv_splitter = self.get_cv_splitter(space['k_split'], int(space['k_folds']))\n",
    "            \n",
    "            # Prepare XGBoost parameters\n",
    "            params = {\n",
    "                'objective': 'binary:logistic',\n",
    "                'eval_metric': 'auc',\n",
    "                'max_depth': int(space['max_depth']),\n",
    "                'learning_rate': space['learning_rate'],\n",
    "                'subsample': space['subsample'],\n",
    "                'colsample_bytree': space['colsample_bytree'],\n",
    "                'min_child_weight': int(space['min_child_weight']),\n",
    "                'n_estimators': int(space['n_estimators']),\n",
    "                'random_state': space['SEED']\n",
    "            }\n",
    "            \n",
    "            # Cross-validation scores\n",
    "            cv_scores = []\n",
    "            for train_idx, valid_idx in cv_splitter.split(X_train_processed):\n",
    "                X_fold_train = X_train_processed.iloc[train_idx]\n",
    "                y_fold_train = y_train.iloc[train_idx]\n",
    "                X_fold_valid = X_train_processed.iloc[valid_idx]\n",
    "                y_fold_valid = y_train.iloc[valid_idx]\n",
    "                \n",
    "                model = xgb.XGBClassifier(**params)\n",
    "                model.fit(X_fold_train, y_fold_train, eval_set=[(X_fold_valid, y_fold_valid)], \n",
    "                        verbose=False)\n",
    "                \n",
    "                pred_valid = model.predict_proba(X_fold_valid)[:, 1]\n",
    "                cv_scores.append(roc_auc_score(y_fold_valid, pred_valid))\n",
    "            \n",
    "            # Train final model on full training data\n",
    "            model = xgb.XGBClassifier(**params)\n",
    "            model.fit(X_train_processed, y_train, eval_set=[(X_test_processed, y_test)], \n",
    "                     verbose=False)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            metrics = self.evaluate_model(\n",
    "                model, \n",
    "                X_test_processed, y_test,\n",
    "                X_oot_processed, y_oot\n",
    "            )\n",
    "            \n",
    "            metrics['cv_score_mean'] = np.mean(cv_scores)\n",
    "            metrics['cv_score_std'] = np.std(cv_scores)\n",
    "            \n",
    "            return {\n",
    "                'loss': -metrics['cv_score_mean'],  # Optimize for CV performance\n",
    "                'status': STATUS_OK,\n",
    "                'model': model,\n",
    "                'metrics': metrics,\n",
    "                'params': params,\n",
    "                'feature_columns': list(X_train_processed.columns)\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in objective function: {str(e)}\")\n",
    "            return {'loss': 0, 'status': STATUS_OK, 'model': None}\n",
    "\n",
    "    \n",
    "    def optimize_model(self, df, features, target, max_evals=20, model_type = \"\"):\n",
    "        \"\"\"Run complete model optimization pipeline with enhanced search space\"\"\"\n",
    "        # Prepare data\n",
    "        (X_train_valid, y_train_valid), (X_test, y_test), (X_oot, y_oot) = self.prepare_data(\n",
    "            df, features, target\n",
    "        )\n",
    "        if model_type == 'lgbm':\n",
    "        # Define objective function with prepared data\n",
    "            objective = partial(\n",
    "                self.objective_lgb,\n",
    "                X_train=X_train_valid,\n",
    "                y_train=y_train_valid,\n",
    "                X_test=X_test,\n",
    "                y_test=y_test,\n",
    "                X_oot=X_oot,\n",
    "                y_oot=y_oot\n",
    "            )\n",
    "        \n",
    "        if model_type == 'xgb':\n",
    "            objective = partial(\n",
    "                self.objective_xgb,\n",
    "                X_train=X_train_valid,\n",
    "                y_train=y_train_valid,\n",
    "                X_test=X_test,\n",
    "                y_test=y_test,\n",
    "                X_oot=X_oot,\n",
    "                y_oot=y_oot\n",
    "            )\n",
    "        \n",
    "        # Run optimization\n",
    "        trials = Trials()\n",
    "        best = fmin(\n",
    "            fn=objective,\n",
    "            space=self.create_search_space(model_type),\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=max_evals,\n",
    "            trials=trials\n",
    "        )\n",
    "        \n",
    "        # Get best trial\n",
    "        best_trial = sorted(trials.trials, key=lambda x: x['result']['loss'])[0]\n",
    "        \n",
    "        # Store trials history\n",
    "        self.trials_history = pd.DataFrame([\n",
    "            {\n",
    "                **trial['misc']['vals'],\n",
    "                'cv_score': -trial['result']['loss'],\n",
    "                'test_auc': trial['result']['metrics']['test_auc'],\n",
    "                'oot_auc': trial['result']['metrics']['oot_auc'],\n",
    "                **{\n",
    "                    f\"threshold_{threshold}_{metric}_{set_type}\": trial['result']['metrics']['threshold_metrics'][f'threshold_{threshold}'][set_type][metric]\n",
    "                    for threshold in [0.5,0.8, 0.85, 0.9, 0.95]\n",
    "                    for set_type in ['test', 'oot']\n",
    "                    for metric in ['precision', 'recall', 'f1', 'auc']\n",
    "                }\n",
    "            }\n",
    "            for trial in trials.trials\n",
    "            if 'loss' in trial['result']\n",
    "        ])\n",
    "        \n",
    "        return (\n",
    "            best_trial['result']['model'],\n",
    "            best_trial['result']['metrics'],\n",
    "            best_trial['result']['params'],\n",
    "            best_trial['result']['feature_columns']\n",
    "        )\n",
    "    \n",
    "    # EITHER THIS OR SAVE_MODEL -- NEED TO FIX\n",
    "    def save_results(self, model, metrics, params, output_dir):\n",
    "        \"\"\"Save model, parameters and metrics\"\"\"\n",
    "        # Save model\n",
    "        model.save_model(f\"{output_dir}/best_model.txt\")\n",
    "        \n",
    "        # Save parameters\n",
    "        with open(f\"{output_dir}/best_params.json\", 'w') as f:\n",
    "            json.dump(params, f, indent=4)\n",
    "        \n",
    "        # Save metrics\n",
    "        with open(f\"{output_dir}/metrics.json\", 'w') as f:\n",
    "            json.dump(metrics, f, indent=4)\n",
    "    \n",
    "\n",
    "    # Pickling for XGB -- NEED TO FIX\n",
    "    def save_model(self, model, output_dir, model_name='best_model.pkl'):\n",
    "        \"\"\"Save the trained XGBoost model to a pickle file.\"\"\"\n",
    "        with open(f\"{output_dir}/{model_name}\", 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "\n",
    "    def load_model(self, model_path):\n",
    "        \"\"\"Load a trained XGBoost model from a pickle file.\"\"\"\n",
    "        with open(model_path, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = UnifiedModelTrainer(random_state=2024)\n",
    "\n",
    "# Load data\n",
    "df = mds\n",
    "features = [col for col in df.columns if col not in ['account_type', 'X_fold']]\n",
    "target = 'account_type'\n",
    "\n",
    "# Run optimization with extended search space\n",
    "model, metrics, params, selected_features = trainer.optimize_model(\n",
    "    df, features, target, max_evals=10, model_type = 'xgb'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP EXPLAINABILITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(model, \"output_directory\")\n",
    "\n",
    "import shap\n",
    "\n",
    "# Load the model from the pickle file\n",
    "loaded_model = trainer.load_model('output_directory/best_model.pkl')\n",
    "\n",
    "# Assuming you have your data prepared\n",
    "explainer = shap.Explainer(loaded_model)\n",
    "test = df[df['X_fold'] == 'test']\n",
    "X_test = test[features]\n",
    "y_test = test[target]    \n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "# Visualize the SHAP values\n",
    "shap.summary_plot(shap_values, X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To get Features and Metrics of best MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save results -- NEED TO FIX\n",
    "#trainer.save_results(model, metrics, params, \"output_directory\")\n",
    "trainer.save_model(model, metrics, params)\n",
    "trainer.plot_results(metrics, \"output_directory\")\n",
    "\n",
    "# Access trials history\n",
    "print(trainer.trials_history)\n",
    "\n",
    "\n",
    "# Sort trials history by test AUC to get the highest AUC model\n",
    "best_auc_trial = trainer.trials_history.sort_values(by='test_auc', ascending=False).iloc[0]\n",
    "\n",
    "best_auc_trial[['test_auc','threshold_0.5_auc_test','threshold_0.8_auc_test',\n",
    "       'threshold_0.8_auc_oot',\n",
    "       'threshold_0.85_auc_test',\n",
    "       'threshold_0.85_auc_oot',\n",
    "       'threshold_0.9_auc_test',\n",
    "       'threshold_0.9_auc_oot',\n",
    "       'threshold_0.95_auc_test',\n",
    "       'threshold_0.95_auc_oot']]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
