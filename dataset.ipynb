{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries and Data\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "import scorecardpy as sc\n",
    "import warnings \n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "df = pd.read_csv(\"/Users/wenwei/Documents/Sku/y4s1/bt4222/project/twitter_human_bots_dataset.csv\")\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provided Features\n",
    "* created_at: timestamp\n",
    "    * Day account was created\n",
    "\n",
    "* default_profile: Boolean\n",
    "    * Indicating whether the account has a default profile\n",
    "\n",
    "* default_profile_image: Boolean\n",
    "    * Indicating whether the account has a default image profile\n",
    "\n",
    "* description: String\n",
    "    * User account description\n",
    "\n",
    "* favourites_count: Int\n",
    "    * Total number of favourite tweets\n",
    "\n",
    "* followers_count: Int\n",
    "    * Total number of followers\n",
    "\n",
    "* friend_count: Int\n",
    "    * Total number of friends (people who follow back)\n",
    "\n",
    "* geo_enabled: Boolean\n",
    "    * Indicating whether the account has the geographic location enabled\n",
    "\n",
    "* id: string\n",
    "    * unique identifier of the account\n",
    "\n",
    "* lang: string\n",
    "    * Language of the account\n",
    "\n",
    "* location: \n",
    "    * Location of the account\n",
    "\n",
    "* profile_background: string\n",
    "    * Profile background image url\n",
    "\n",
    "* profile_image_url: String\n",
    "    * Profile image URL\n",
    "\n",
    "* screen_name: string\n",
    "    * username\n",
    "\n",
    "* statuses_count: int\n",
    "    * Total number of tweets\n",
    "\n",
    "* verified: Boolean\n",
    "    * Indicating whether the account has been verified\n",
    "\n",
    "* average_tweets_per_day: int\n",
    "    * Average tweets posted per day (statuses_count / account_age_day)\n",
    "\n",
    "* account_age_day: int\n",
    "    * Account age measured in days\n",
    "\n",
    "* account_type: binary\n",
    "    * account type, bot or human\n",
    "\n",
    "### Transformed Features to consider:\n",
    "* Sentiment analysis for description\n",
    "* Number of mentions in description to other bot accounts\n",
    "* Length of description\n",
    "* Ratio Followers_count to friends count\n",
    "* Ratio of Followers_count to tweets per day\n",
    "* Ratio of friends to tweets per day\n",
    "* Ratio of tweets since account created\n",
    "* Time when account was created (Past midnight of timezone, obtained from location)\n",
    "* Standard deviation of avg tweets from avg tweets of bots\n",
    "\n",
    "### Total Features: 18 (provided) + 9 (created)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure of ML Process\n",
    "\n",
    "## Data\n",
    "* Data Cleaning, Imputation, etc..\n",
    "* Train Test split (based on account creation date)\n",
    "* 2006-2017 used to train,test validate model\n",
    "* 2018-2019, out of sample testing, to test how well model performs with more recent data\n",
    "\n",
    "## Features\n",
    "* Feature Creation\n",
    "* Feature Reduction (using Weight of Evidence(woe) check for feature importance, Correlation)\n",
    "* Run feature selection using tree base algo (random forest or smth)\n",
    "\n",
    "## Model training\n",
    "\n",
    "### Tree based models\n",
    "* XGB, LGBM, RF, ETC, DT\n",
    "\n",
    "### Neural Networks\n",
    "* NN, autoencoders(?), GNN\n",
    "\n",
    "---\n",
    "\n",
    "### Get Shap for model explanability both local and global\n",
    "* Tune model on best model selected (either on precision/f1/recall and feature blend)\n",
    "\n",
    "### Test model on out of sample set\n",
    "* Get metrics(acc,precision,f1, etc..) from out of sample set\n",
    "\n",
    "### Dashboard(?) --enhancement\n",
    "* Transfer results to a dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                         0\n",
       "created_at                         0\n",
       "default_profile                    0\n",
       "default_profile_image              0\n",
       "description                     7257\n",
       "favourites_count                   0\n",
       "followers_count                    0\n",
       "friends_count                      0\n",
       "geo_enabled                        0\n",
       "id                                 0\n",
       "lang                            7957\n",
       "location                           4\n",
       "profile_background_image_url    4499\n",
       "profile_image_url                  1\n",
       "screen_name                        0\n",
       "statuses_count                     0\n",
       "verified                           0\n",
       "average_tweets_per_day             0\n",
       "account_age_days                   0\n",
       "account_type                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for Null Values\n",
    "missing_values = df.isnull().sum()\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How WOE works:\n",
    "Run the features you want to conduct weight of evidence on. For example, I put the features in temp_list and then created a dataframe containing only those features in df_tmp.\n",
    "\n",
    "* Step 1: Replace temp_list with your features\n",
    "* Step 2: Run code chunk below\n",
    "* Step 3: Look at the WOE score for each bin of each feature to interpret WOE results\n",
    "\n",
    "How to Interpret WOE scores\n",
    "Negative or Positive Values indicate the direction of the feature while the magnitude indicate the strength of the feature.\n",
    "E.g For the feature \"statuses_count\", if the woe score for one of its bin is 0.5 it indicates that for that bin, the feature \"statuses_count\" identifies many bots.\n",
    "Conversely if the woe score for one of its bin is -0.7, it means that the feature is not good a predicting bots.\n",
    "\n",
    "Also do look at the IV scores to determine the features contribution. Generally an IV of >0.02 indicates weak predictive power while >0.5 indicates strong predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating woe binning ...\n",
      "Binning for statuses_count:\n",
      "         variable               bin  count  count_distr   good   bad  \\\n",
      "0  statuses_count     [-inf,4000.0)  18354     0.490251   9254  9100   \n",
      "1  statuses_count  [4000.0,65000.0)  16356     0.436882  13827  2529   \n",
      "2  statuses_count     [65000.0,inf)   2728     0.072867   1932   796   \n",
      "\n",
      "    badprob       woe    bin_iv  total_iv   breaks  is_special_values  \n",
      "0  0.495805  0.682904  0.247503  0.598909   4000.0              False  \n",
      "1  0.154622 -0.999114  0.348942  0.598909  65000.0              False  \n",
      "2  0.291789 -0.187027  0.002464  0.598909      inf              False  \n",
      "Binning for favourites_count:\n",
      "           variable              bin  count  count_distr   good    bad  \\\n",
      "0  favourites_count    [-inf,3000.0)  22524     0.601635  11704  10820   \n",
      "1  favourites_count  [3000.0,5000.0)   2707     0.072306   2167    540   \n",
      "2  favourites_count     [5000.0,inf)  12207     0.326059  11142   1065   \n",
      "\n",
      "    badprob       woe    bin_iv  total_iv  breaks  is_special_values  \n",
      "0  0.480376  0.621151  0.250267  0.872914  3000.0              False  \n",
      "1  0.199483 -0.689845  0.029783  0.872914  5000.0              False  \n",
      "2  0.087245 -1.648062  0.592864  0.872914     inf              False  \n",
      "Binning for followers_count:\n",
      "          variable             bin  count  count_distr   good    bad  \\\n",
      "0  followers_count    [-inf,500.0)  20173     0.538838   9881  10292   \n",
      "1  followers_count  [500.0,1500.0)   4511     0.120493   3685    826   \n",
      "2  followers_count    [1500.0,inf)  12754     0.340670  11447   1307   \n",
      "\n",
      "    badprob       woe    bin_iv  total_iv  breaks  is_special_values  \n",
      "0  0.510187  0.740438  0.320829  0.903372   500.0              False  \n",
      "1  0.183108 -0.795746  0.064332  0.903372  1500.0              False  \n",
      "2  0.102478 -1.470308  0.518211  0.903372     inf              False  \n",
      "Binning for friends_count:\n",
      "        variable            bin  count  count_distr   good   bad   badprob  \\\n",
      "0  friends_count   [-inf,100.0)  12421     0.331775   4476  7945  0.639643   \n",
      "1  friends_count  [100.0,300.0)   6402     0.171003   4733  1669  0.260700   \n",
      "2  friends_count    [300.0,inf)  18615     0.497222  15804  2811  0.151007   \n",
      "\n",
      "        woe    bin_iv  total_iv breaks  is_special_values  \n",
      "0  1.273498  0.586433  1.021803  100.0              False  \n",
      "1 -0.342649  0.018810  1.021803  300.0              False  \n",
      "2 -1.027038  0.416560  1.021803    inf              False  \n"
     ]
    }
   ],
   "source": [
    "temp_lst = ['favourites_count', 'followers_count','friends_count','account_type','statuses_count']\n",
    "#Transforming Bot/Human to 1s and 0s\n",
    "df['account_type'] = df['account_type'].replace({'bot': 1, 'human': 0})\n",
    "\n",
    "# Replace 'target' with actual column name\n",
    "y = df['account_type']  \n",
    "# Drop target to leave only features\n",
    "X = df.drop(columns=['account_type'])  \n",
    "\n",
    "df_tmp = df[temp_lst]\n",
    "# Conduct the binning process using woebin\n",
    "bins = sc.woebin(df_tmp, y='account_type', bins = 5)\n",
    "\n",
    "# Display the binning information (optional to view WoE values per variable)\n",
    "for key in bins.keys():\n",
    "    print(f\"Binning for {key}:\")\n",
    "    print(bins[key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n        'created_at', 'default_profile', 'default_profile_image',\\n       'description', 'favourites_count', 'followers_count', 'friends_count',\\n       'geo_enabled', 'id', 'lang', 'location', 'profile_background_image_url',\\n       'profile_image_url', 'screen_name', 'statuses_count', 'verified',\\n       'average_tweets_per_day', 'account_age_days', 'account_type'\\n\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.shape\n",
    "\n",
    "#Transforming features\n",
    "#tagging of description, construct some sort NLA\n",
    "#text analysis for description\n",
    "#ratio followers_count to friends count\n",
    "#ratio of followers to tweets per day\n",
    "# ratio of friends to tweets per day\n",
    "#length of descriptions\n",
    "\"\"\"\n",
    "        'created_at', 'default_profile', 'default_profile_image',\n",
    "       'description', 'favourites_count', 'followers_count', 'friends_count',\n",
    "       'geo_enabled', 'id', 'lang', 'location', 'profile_background_image_url',\n",
    "       'profile_image_url', 'screen_name', 'statuses_count', 'verified',\n",
    "       'average_tweets_per_day', 'account_age_days', 'account_type'\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = pd.to_datetime(df['created_at']).dt.year\n",
    "year_distribution = df['year'].value_counts().sort_index()\n",
    "year_distribution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
