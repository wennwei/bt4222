{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import file here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df = pd.read_csv(\"/Users/wenwei/Documents/Sku/y4s1/bt4222/project/twitter_human_bots_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert 'created_at' to datetime\n",
    "df['created_at'] = pd.to_datetime(df['created_at'], errors='coerce')\n",
    "\n",
    "# Calculate Account Age\n",
    "current_time = datetime.now()\n",
    "df['account_age_days'] = (current_time - df['created_at']).dt.days\n",
    "\n",
    "# Time-Based Features\n",
    "df['creation_hour'] = df['created_at'].dt.hour\n",
    "df['creation_day_of_week'] = df['created_at'].dt.dayofweek\n",
    "df['creation_month'] = df['created_at'].dt.month\n",
    "df['creation_year'] = df['created_at'].dt.year\n",
    "df['creation_quarter'] = df['created_at'].dt.quarter\n",
    "df['is_weekend'] = df['creation_day_of_week'] >= 5\n",
    "df['creation_week_of_year'] = df['created_at'].dt.isocalendar().week\n",
    "df['is_beginning_of_month'] = df['created_at'].dt.day <= 5\n",
    "df['is_end_of_month'] = df['created_at'].dt.day >= 26\n",
    "\n",
    "# Define part of day based on hour\n",
    "def part_of_day(hour):\n",
    "    if 5 <= hour < 12:\n",
    "        return 'Morning'\n",
    "    elif 12 <= hour < 17:\n",
    "        return 'Afternoon'\n",
    "    elif 17 <= hour < 21:\n",
    "        return 'Evening'\n",
    "    else:\n",
    "        return 'Night'\n",
    "\n",
    "df['part_of_day'] = df['creation_hour'].apply(part_of_day)\n",
    "\n",
    "# Additional Features\n",
    "humans_mean = df[df['account_type'] == 'human']['average_tweets_per_day'].mean()\n",
    "humans_std = df[df['account_type'] == 'human']['average_tweets_per_day'].std()\n",
    "df['deviation_from_humans'] = (df['average_tweets_per_day'] - humans_mean) / humans_std\n",
    "\n",
    "# Description Length Feature\n",
    "df['description_length'] = df['description'].apply(lambda x: len(str(x)) if pd.notnull(x) else 0)\n",
    "\n",
    "# Followers/Friends Ratios\n",
    "df['followers_to_friends_ratio'] = df['followers_count'] / df['friends_count']\n",
    "df['followers_to_friends_ratio'].fillna(0, inplace=True)\n",
    "\n",
    "# Followers to Tweets Per Day Ratio\n",
    "df['followers_to_tweets_per_day_ratio'] = df['followers_count'] / df['average_tweets_per_day']\n",
    "df['followers_to_tweets_per_day_ratio'].fillna(0, inplace=True)\n",
    "\n",
    "# Mentions Count in Description\n",
    "import re\n",
    "\n",
    "def extract_mentions(description):\n",
    "    return re.findall(r'@\\w+', str(description))\n",
    "\n",
    "df['mentions'] = df['description'].apply(extract_mentions)\n",
    "df['mention_count'] = df['mentions'].apply(len)\n",
    "\n",
    "# Ensure any remaining NaN values are filled if necessary\n",
    "########################################################################\n",
    "# TO DISCUSS METHOD OF IMPUTATION\n",
    "########################################################################\n",
    "df.fillna(0, inplace=True)\n",
    "df.replace(np.inf,0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENCODING METHOD FOR LANG AND LOCATION TO BE DISCUSSSED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding Categorical Features\n",
    "df['account_type'] = df['account_type'].map({'human': 0, 'bot': 1})\n",
    "\n",
    "encode_cols = ['default_profile', 'default_profile_image', 'geo_enabled', 'lang', 'location', 'verified',\n",
    "               'creation_year', 'is_weekend', 'is_beginning_of_month', 'is_end_of_month', 'part_of_day']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for col in encode_cols:\n",
    "    df[col] = label_encoder.fit_transform(df[col].astype(str))  # Convert to string to handle NaNs if any\n",
    "\n",
    "\n",
    "# Define Feature Columns and Target\n",
    "id_col = ['id']\n",
    "labels = ['account_type']\n",
    "predictive_cols = ['default_profile', 'default_profile_image', 'favourites_count', 'followers_count', 'friends_count',\n",
    "                   'geo_enabled', 'lang', 'location', 'statuses_count', 'verified', 'average_tweets_per_day', \n",
    "                   'account_age_days', 'creation_hour', 'creation_day_of_week', 'creation_month', 'creation_year',\n",
    "                   'creation_quarter', 'is_weekend', 'creation_week_of_year', 'is_beginning_of_month', \n",
    "                   'is_end_of_month', 'part_of_day', 'deviation_from_humans', 'description_length', \n",
    "                   'followers_to_friends_ratio', 'followers_to_tweets_per_day_ratio', 'mention_count','account_type']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set cutoff date for training/validation split\n",
    "cutoff_date = pd.to_datetime('2017-01-01')\n",
    "df['date'] = pd.to_datetime(df['created_at'])\n",
    "\n",
    "# Split data based on cutoff date\n",
    "oot = df[df['date'] >= cutoff_date].set_index('id')\n",
    "df_model = df[df['date'] < cutoff_date].set_index('id')\n",
    "\n",
    "# Train, Test, Validation Splits\n",
    "RANDOM_SEED = 2024\n",
    "train, test = train_test_split(df_model, test_size=0.2, random_state=RANDOM_SEED)\n",
    "train, valid = train_test_split(train, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "# Add 'X_fold' columns for each split\n",
    "train['X_fold'] = 'train'\n",
    "test['X_fold'] = 'test'\n",
    "valid['X_fold'] = 'valid'\n",
    "oot['X_fold'] = 'oot'\n",
    "\n",
    "# Combine all datasets for modeling\n",
    "mds = pd.concat([train, test, valid, oot]).copy(deep=True)\n",
    "mds = mds.reset_index()\n",
    "\n",
    "# Plot correlation heatmap for predictive columns\n",
    "corr = mds[predictive_cols].corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Heatmap of Predictive Features')\n",
    "plt.show()\n",
    "\n",
    "# Check target distribution\n",
    "print(mds['account_type'].value_counts())\n",
    "\n",
    "# Final Data Overview\n",
    "print(mds.head())\n",
    "print(mds.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "from hyperopt import hp\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import custom functions\n",
    "from utils import mpr_report, final_fitting\n",
    "\n",
    "from lmf2 import LoadModelFunction#, final_fitting\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import time\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import json\n",
    "from functools import partial\n",
    "\n",
    "def objective_lgb(space, train_data, valid_data, X_test, y_test, X_oot, y_oot):\n",
    "    \"\"\"Objective function for LightGBM optimization\"\"\"\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': int(space['num_leaves']),\n",
    "        'learning_rate': space['learning_rate'],\n",
    "        'feature_fraction': space['feature_fraction'],\n",
    "        'bagging_fraction': space['bagging_fraction'],\n",
    "        'bagging_freq': int(space['bagging_freq']),\n",
    "        'min_child_samples': int(space['min_child_samples']),\n",
    "        'max_depth': int(space['max_depth']),\n",
    "        'verbose': -1,\n",
    "        'random_state': 2024\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            num_boost_round=1000,\n",
    "            valid_sets=[train_data, valid_data],\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(stopping_rounds=50),\n",
    "                lgb.log_evaluation(period=100)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        pred_test = model.predict(X_test)\n",
    "        pred_oot = model.predict(X_oot)\n",
    "        \n",
    "        test_auc = roc_auc_score(y_test, pred_test)\n",
    "        oot_auc = roc_auc_score(y_oot, pred_oot)\n",
    "        \n",
    "        return {\n",
    "            'loss': -test_auc,\n",
    "            'status': STATUS_OK,\n",
    "            'model': model,\n",
    "            'test_auc': test_auc,\n",
    "            'oot_auc': oot_auc,\n",
    "            'params': params,\n",
    "            'model_type': 'lgb'\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error in LightGBM training: {str(e)}\")\n",
    "        return {'loss': 0, 'status': STATUS_OK, 'model': None, 'test_auc': 0, 'oot_auc': 0, 'params': params, 'model_type': 'lgb'}\n",
    "\n",
    "def objective_xgb(space, X_train, y_train, X_valid, y_valid, X_test, y_test, X_oot, y_oot):\n",
    "    \"\"\"Objective function for XGBoost optimization\"\"\"\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc',\n",
    "        'max_depth': int(space['max_depth']),\n",
    "        'learning_rate': space['learning_rate'],\n",
    "        'subsample': space['subsample'],\n",
    "        'colsample_bytree': space['colsample_bytree'],\n",
    "        'min_child_weight': int(space['min_child_weight']),\n",
    "        'n_estimators': int(space['n_estimators']),\n",
    "        'random_state': 2024,\n",
    "        'use_label_encoder': False  # Prevent warning about label encoder\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        model = xgb.XGBClassifier(**params)\n",
    "        \n",
    "        # Fit model\n",
    "        model.fit(\n",
    "            X_train, \n",
    "            y_train,\n",
    "            eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        # Make predictions\n",
    "        pred_test = model.predict_proba(X_test)[:, 1]\n",
    "        pred_oot = model.predict_proba(X_oot)[:, 1]\n",
    "        \n",
    "        test_auc = roc_auc_score(y_test, pred_test)\n",
    "        oot_auc = roc_auc_score(y_oot, pred_oot)\n",
    "        \n",
    "        return {\n",
    "            'loss': -test_auc,\n",
    "            'status': STATUS_OK,\n",
    "            'model': model,\n",
    "            'test_auc': test_auc,\n",
    "            'oot_auc': oot_auc,\n",
    "            'params': params,\n",
    "            'model_type': 'xgb'\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error in XGBoost training: {str(e)}\")\n",
    "        return {'loss': 0, 'status': STATUS_OK, 'model': None, 'test_auc': 0, 'oot_auc': 0, \n",
    "                'params': params, 'model_type': 'xgb'}\n",
    "\n",
    "def objective_rf(space, X_train, y_train, X_valid, y_valid, X_test, y_test, X_oot, y_oot):\n",
    "    \"\"\"Objective function for Random Forest optimization\"\"\"\n",
    "    params = {\n",
    "        'n_estimators': int(space['n_estimators']),\n",
    "        'max_depth': int(space['max_depth']) if space['max_depth'] is not None else None,\n",
    "        'min_samples_split': int(space['min_samples_split']),\n",
    "        'min_samples_leaf': int(space['min_samples_leaf']),\n",
    "        'max_features': space['max_features'],\n",
    "        'random_state': 2024,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        model = RandomForestClassifier(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        pred_test = model.predict_proba(X_test)[:, 1]\n",
    "        pred_oot = model.predict_proba(X_oot)[:, 1]\n",
    "        \n",
    "        test_auc = roc_auc_score(y_test, pred_test)\n",
    "        oot_auc = roc_auc_score(y_oot, pred_oot)\n",
    "        \n",
    "        return {\n",
    "            'loss': -test_auc,\n",
    "            'status': STATUS_OK,\n",
    "            'model': model,\n",
    "            'test_auc': test_auc,\n",
    "            'oot_auc': oot_auc,\n",
    "            'params': params,\n",
    "            'model_type': 'rf'\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error in Random Forest training: {str(e)}\")\n",
    "        return {'loss': 0, 'status': STATUS_OK, 'model': None, 'test_auc': 0, 'oot_auc': 0, 'params': params, 'model_type': 'rf'}\n",
    "\n",
    "def hyperopt_tuning(mds, predictive_cols, max_evals=50, random_state=2024):\n",
    "    \"\"\"Perform hyperparameter tuning for all models using Hyperopt\"\"\"\n",
    "    features = [col for col in predictive_cols if col != 'account_type']\n",
    "    \n",
    "    # Prepare datasets\n",
    "    X_train = mds[mds['X_fold'] == 'train'][features]\n",
    "    y_train = mds[mds['X_fold'] == 'train']['account_type']\n",
    "    \n",
    "    X_valid = mds[mds['X_fold'] == 'valid'][features]\n",
    "    y_valid = mds[mds['X_fold'] == 'valid']['account_type']\n",
    "    \n",
    "    X_test = mds[mds['X_fold'] == 'test'][features]\n",
    "    y_test = mds[mds['X_fold'] == 'test']['account_type']\n",
    "    \n",
    "    X_oot = mds[mds['X_fold'] == 'oot'][features]\n",
    "    y_oot = mds[mds['X_fold'] == 'oot']['account_type']\n",
    "    \n",
    "    # Create LightGBM datasets\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)\n",
    "    \n",
    "    # Define search spaces for each model\n",
    "    space_lgb = {\n",
    "        'num_leaves': hp.quniform('num_leaves', 15, 127, 1),\n",
    "        'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "        'feature_fraction': hp.uniform('feature_fraction', 0.6, 0.9),\n",
    "        'bagging_fraction': hp.uniform('bagging_fraction', 0.6, 0.9),\n",
    "        'bagging_freq': hp.quniform('bagging_freq', 2, 10, 1),\n",
    "        'min_child_samples': hp.quniform('min_child_samples', 10, 150, 1),\n",
    "        'max_depth': hp.quniform('max_depth', 3, 12, 1)\n",
    "    }\n",
    "    \n",
    "    space_xgb = {\n",
    "        'max_depth': hp.quniform('max_depth', 3, 12, 1),\n",
    "        'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "        'subsample': hp.uniform('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': hp.uniform('colsample_bytree', 0.6, 1.0),\n",
    "        'min_child_weight': hp.quniform('min_child_weight', 1, 7, 1),\n",
    "        'n_estimators': hp.quniform('n_estimators', 100, 1000, 50)\n",
    "    }\n",
    "    \n",
    "    space_rf = {\n",
    "        'n_estimators': hp.quniform('n_estimators', 100, 500, 50),\n",
    "        'max_depth': hp.choice('max_depth', [None] + list(range(10, 31, 2))),\n",
    "        'min_samples_split': hp.quniform('min_samples_split', 2, 20, 1),\n",
    "        'min_samples_leaf': hp.quniform('min_samples_leaf', 1, 10, 1),\n",
    "        'max_features': hp.choice('max_features', ['sqrt', 'log2'])\n",
    "    }\n",
    "    \n",
    "    models_config = [\n",
    "        {\n",
    "            'name': 'LightGBM',\n",
    "            'objective': partial(\n",
    "                objective_lgb,\n",
    "                train_data=train_data,\n",
    "                valid_data=valid_data,\n",
    "                X_test=X_test,\n",
    "                y_test=y_test,\n",
    "                X_oot=X_oot,\n",
    "                y_oot=y_oot\n",
    "            ),\n",
    "            'space': space_lgb\n",
    "        },\n",
    "        {\n",
    "            'name': 'XGBoost',\n",
    "            'objective': partial(\n",
    "                objective_xgb,\n",
    "                X_train=X_train,\n",
    "                y_train=y_train,\n",
    "                X_valid=X_valid,\n",
    "                y_valid=y_valid,\n",
    "                X_test=X_test,\n",
    "                y_test=y_test,\n",
    "                X_oot=X_oot,\n",
    "                y_oot=y_oot\n",
    "            ),\n",
    "            'space': space_xgb\n",
    "        },\n",
    "        {\n",
    "            'name': 'Random Forest',\n",
    "            'objective': partial(\n",
    "                objective_rf,\n",
    "                X_train=X_train,\n",
    "                y_train=y_train,\n",
    "                X_valid=X_valid,\n",
    "                y_valid=y_valid,\n",
    "                X_test=X_test,\n",
    "                y_test=y_test,\n",
    "                X_oot=X_oot,\n",
    "                y_oot=y_oot\n",
    "            ),\n",
    "            'space': space_rf\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    best_models = {}\n",
    "    all_trials_dfs = {}\n",
    "    \n",
    "    for model_config in models_config:\n",
    "        print(f\"\\nOptimizing {model_config['name']}...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        trials = Trials()\n",
    "        best = fmin(\n",
    "            fn=model_config['objective'],\n",
    "            space=model_config['space'],\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=max_evals,\n",
    "            trials=trials\n",
    "        )\n",
    "        \n",
    "        print(f\"{model_config['name']} optimization completed in {(time.time() - start_time)/60:.2f} minutes\")\n",
    "        \n",
    "        # Get best trial\n",
    "        best_trial = sorted(trials.trials, key=lambda x: x['result']['loss'])[0]\n",
    "        best_models[model_config['name']] = {\n",
    "            'model': best_trial['result']['model'],\n",
    "            'params': best_trial['result']['params'],\n",
    "            'test_auc': best_trial['result']['test_auc'],\n",
    "            'oot_auc': best_trial['result']['oot_auc']\n",
    "        }\n",
    "        \n",
    "        # Convert trials to DataFrame\n",
    "        trials_df = pd.DataFrame([\n",
    "            {\n",
    "                **trial['misc']['vals'],\n",
    "                'test_auc': -trial['result']['loss'],\n",
    "                'oot_auc': trial['result']['oot_auc']\n",
    "            }\n",
    "            for trial in trials.trials\n",
    "        ])\n",
    "        \n",
    "        # Flatten lists in DataFrame\n",
    "        for col in trials_df.columns:\n",
    "            if isinstance(trials_df[col].iloc[0], list):\n",
    "                trials_df[col] = trials_df[col].apply(lambda x: x[0])\n",
    "        \n",
    "        all_trials_dfs[model_config['name']] = trials_df\n",
    "    \n",
    "    # Compare models\n",
    "    print(\"\\nModel Comparison:\")\n",
    "    comparison_df = pd.DataFrame({\n",
    "        model_name: {\n",
    "            'Test AUC': info['test_auc'],\n",
    "            'OOT AUC': info['oot_auc']\n",
    "        }\n",
    "        for model_name, info in best_models.items()\n",
    "    }).T\n",
    "    print(comparison_df)\n",
    "    \n",
    "    # Plot model comparison\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    comparison_df.plot(kind='bar')\n",
    "    plt.title('Model Performance Comparison')\n",
    "    plt.ylabel('AUC Score')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return best_models, all_trials_dfs, comparison_df\n",
    "\n",
    "def save_results(best_models, all_trials_dfs, comparison_df, filename_prefix='model_comparison'):\n",
    "    \"\"\"Save all models and results\"\"\"\n",
    "    # Save models\n",
    "    for model_name, model_info in best_models.items():\n",
    "        if model_info['model'] is not None:\n",
    "            if model_name == 'LightGBM':\n",
    "                model_info['model'].save_model(f\"{filename_prefix}_{model_name.lower()}_model.txt\")\n",
    "            else:\n",
    "                # For XGBoost and Random Forest, use joblib\n",
    "                import joblib\n",
    "                joblib.dump(model_info['model'], f\"{filename_prefix}_{model_name.lower()}_model.joblib\")\n",
    "    \n",
    "    # Save best parameters\n",
    "    with open(f\"{filename_prefix}_best_params.json\", 'w') as f:\n",
    "        json.dump({name: info['params'] for name, info in best_models.items()}, f, indent=4)\n",
    "    \n",
    "    # Save all trials results\n",
    "    for model_name, trials_df in all_trials_dfs.items():\n",
    "        trials_df.to_csv(f\"{filename_prefix}_{model_name.lower()}_trials.csv\", index=False)\n",
    "    \n",
    "    # Save model comparison\n",
    "    comparison_df.to_csv(f\"{filename_prefix}_comparison.csv\")\n",
    "    \n",
    "    print(f\"Results saved with prefix: {filename_prefix}\")\n",
    "\n",
    "# Main execution\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    def plot_feature_importance(model, features, model_name, top_n=20):\n",
    "        \"\"\"Plot feature importance for a given model\"\"\"\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        if model_name == 'LightGBM':\n",
    "            importance = model.feature_importance(importance_type='gain')\n",
    "            feat_imp = pd.DataFrame({'feature': features, 'importance': importance})\n",
    "        elif model_name == 'XGBoost':\n",
    "            importance = model.feature_importances_\n",
    "            feat_imp = pd.DataFrame({'feature': features, 'importance': importance})\n",
    "        else:  # Random Forest\n",
    "            importance = model.feature_importances_\n",
    "            feat_imp = pd.DataFrame({'feature': features, 'importance': importance})\n",
    "        \n",
    "        feat_imp = feat_imp.sort_values('importance', ascending=False)\n",
    "        \n",
    "        sns.barplot(x='importance', y='feature', data=feat_imp.head(top_n))\n",
    "        plt.title(f'Top {top_n} Feature Importance - {model_name}')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'feature_importance_{model_name.lower()}.png')\n",
    "        plt.close()\n",
    "    \n",
    "    def evaluate_model(model, X, y, model_name, dataset_name):\n",
    "        \"\"\"Evaluate a model on a given dataset\"\"\"\n",
    "        if model_name == 'LightGBM':\n",
    "            pred_proba = model.predict(X)\n",
    "        else:\n",
    "            pred_proba = model.predict_proba(X)[:, 1]\n",
    "            \n",
    "        pred_binary = (pred_proba > 0.5).astype(int)\n",
    "        \n",
    "        metrics = {\n",
    "            'Accuracy': accuracy_score(y, pred_binary),\n",
    "            'Precision': precision_score(y, pred_binary),\n",
    "            'Recall': recall_score(y, pred_binary),\n",
    "            'F1 Score': f1_score(y, pred_binary),\n",
    "            'ROC AUC': roc_auc_score(y, pred_proba)\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{model_name} - {dataset_name} Results:\")\n",
    "        for metric_name, value in metrics.items():\n",
    "            print(f\"{metric_name}: {value:.4f}\")\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    try:\n",
    "        # Load your dataset (assuming you have a function or way to load it)\n",
    "        # This should be replaced with your actual data loading code\n",
    "        print(\"Loading dataset...\")\n",
    "        # mds = load_dataset()  # Replace with your data loading\n",
    "        # predictive_cols = list(mds.columns)  # Adjust based on your actual columns\n",
    "        \n",
    "        # Set parameters for the hyperparameter optimization\n",
    "        max_evals = 50  # Number of trials for each model\n",
    "        random_state = 2024\n",
    "        \n",
    "        print(f\"\\nStarting hyperparameter optimization with {max_evals} evaluations per model...\")\n",
    "        \n",
    "        # Run hyperparameter tuning for all models\n",
    "        best_models, all_trials_dfs, comparison_df = hyperopt_tuning(\n",
    "            mds=mds,  # Your dataset\n",
    "            predictive_cols=predictive_cols,  # Your feature columns\n",
    "            max_evals=max_evals,\n",
    "            random_state=random_state\n",
    "        )\n",
    "        \n",
    "        # Save all results\n",
    "        save_results(best_models, all_trials_dfs, comparison_df)\n",
    "        \n",
    "        # Plot feature importance for each model\n",
    "        features = [col for col in predictive_cols if col != 'account_type']\n",
    "        for model_name, model_info in best_models.items():\n",
    "            if model_info['model'] is not None:\n",
    "                plot_feature_importance(model_info['model'], features, model_name)\n",
    "        \n",
    "        # Create detailed evaluation for each model\n",
    "        datasets = {\n",
    "            'Train': (X_train, y_train),\n",
    "            'Valid': (X_valid, y_valid),\n",
    "            'Test': (X_test, y_test),\n",
    "            'OOT': (X_oot, y_oot)\n",
    "        }\n",
    "        \n",
    "        all_metrics = {}\n",
    "        for model_name, model_info in best_models.items():\n",
    "            if model_info['model'] is not None:\n",
    "                model_metrics = {}\n",
    "                for dataset_name, (X, y) in datasets.items():\n",
    "                    model_metrics[dataset_name] = evaluate_model(\n",
    "                        model_info['model'],\n",
    "                        X, y,\n",
    "                        model_name,\n",
    "                        dataset_name\n",
    "                    )\n",
    "                all_metrics[model_name] = model_metrics\n",
    "        \n",
    "        # Save detailed metrics\n",
    "        with open('detailed_metrics.json', 'w') as f:\n",
    "            json.dump(all_metrics, f, indent=4)\n",
    "        \n",
    "        # Plot learning curves from trials\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        for model_name, trials_df in all_trials_dfs.items():\n",
    "            plt.plot(trials_df['test_auc'].rolling(window=5).mean(), \n",
    "                    label=f'{model_name} (Test AUC)')\n",
    "        plt.title('Learning Curves - Test AUC (Rolling Mean)')\n",
    "        plt.xlabel('Trial')\n",
    "        plt.ylabel('AUC Score')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('learning_curves.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # Print final model comparison\n",
    "        print(\"\\nFinal Model Comparison:\")\n",
    "        print(comparison_df)\n",
    "        \n",
    "        # Identify best overall model\n",
    "        best_model_name = comparison_df['Test AUC'].idxmax()\n",
    "        print(f\"\\nBest performing model: {best_model_name}\")\n",
    "        print(f\"Best model parameters:\")\n",
    "        print(json.dumps(best_models[best_model_name]['params'], indent=2))\n",
    "        \n",
    "        print(\"\\nOptimization pipeline completed successfully!\")\n",
    "        print(\"Results have been saved to files with detailed metrics and visualizations.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in main execution: {str(e)}\")\n",
    "        raise"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
