{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries and Data\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "import scorecardpy as sc\n",
    "import warnings \n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "df = pd.read_csv(\"source data/twitter_human_bots_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "* Feature Creation\n",
    "* Feature Reduction (using Weight of Evidence(woe) check for feature importance, Correlation)\n",
    "* Run feature selection using tree base algo (random forest or smth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformed Features to consider:\n",
    "* Sentiment analysis for description\n",
    "* Number of mentions in description to other bot accounts\n",
    "* Length of description\n",
    "* Ratio Followers_count to friends count\n",
    "* Ratio of Followers_count to tweets per day\n",
    "* Ratio of friends to tweets per day\n",
    "* Ratio of tweets since account created\n",
    "* Time when account was created (Past midnight of timezone, obtained from location)\n",
    "* Standard deviation of avg tweets from avg tweets of bots\n",
    "\n",
    "<b>Total Features: 18 (provided) + 9 (created)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2006      13\n",
       "2007     354\n",
       "2008    1447\n",
       "2009    7598\n",
       "2010    4668\n",
       "2011    5550\n",
       "2012    4594\n",
       "2013    3013\n",
       "2014    2476\n",
       "2015    2140\n",
       "2016    2276\n",
       "2017    2445\n",
       "2018     835\n",
       "2019      29\n",
       "Name: year, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "\n",
    "current_time = datetime.now()\n",
    "df['account_age_days'] = (current_time - df['created_at']).dt.days\n",
    "\n",
    "df['creation_hour'] = df['created_at'].dt.hour\n",
    "\n",
    "df['creation_day_of_week'] = df['created_at'].dt.dayofweek\n",
    "\n",
    "df['creation_month'] = df['created_at'].dt.month\n",
    "\n",
    "df['creation_year'] = df['created_at'].dt.year\n",
    "\n",
    "df['is_weekend'] = df['created_at'].dt.dayofweek >= 5\n",
    "\n",
    "df['creation_quarter'] = df['created_at'].dt.quarter\n",
    "\n",
    "def part_of_day(hour):\n",
    "    if 5 <= hour < 12:\n",
    "        return 'Morning'\n",
    "    elif 12 <= hour < 17:\n",
    "        return 'Afternoon'\n",
    "    elif 17 <= hour < 21:\n",
    "        return 'Evening'\n",
    "    else:\n",
    "        return 'Night'\n",
    "\n",
    "df['part_of_day'] = df['creation_hour'].apply(part_of_day)\n",
    "\n",
    "df['creation_week_of_year'] = df['created_at'].dt.isocalendar().week\n",
    "\n",
    "df['is_beginning_of_month'] = df['created_at'].dt.day <= 5\n",
    "df['is_end_of_month'] = df['created_at'].dt.day >= 26\n",
    "\n",
    "tmp_lst = ['account_age_days','creation_hour','creation_day_of_week','creation_month','creation_year','creation_quarter']\n",
    "tmp_lst_cat = ['is_weekend','part_of_day','is_beginning_of_month','is_end_of_month']\n",
    "df[tmp_lst].describe()\n",
    "df[tmp_lst_cat].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "humans_mean = df[df['account_type'] == 'human']['average_tweets_per_day'].mean()\n",
    "humans_std = df[df['account_type'] == 'human']['average_tweets_per_day'].std()\n",
    "\n",
    "df['deviation_from_humans'] = df['average_tweets_per_day'].apply(\n",
    "    lambda x: (x - humans_mean) / humans_std\n",
    ")\n",
    "\n",
    "df['deviation_from_humans'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Length of Description Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    37438.000000\n",
      "mean        66.878092\n",
      "std         55.092550\n",
      "min          0.000000\n",
      "25%         14.000000\n",
      "50%         58.000000\n",
      "75%        118.000000\n",
      "max        190.000000\n",
      "Name: description_length, dtype: float64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "df['description_length'] = df['description'].apply(lambda x: len(str(x)) if pd.notnull(x) else 0)\n",
    "print(df['description_length'].describe())\n",
    "print(df['description_length'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ratio of Followers_count to tweets per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    3.640400e+04\n",
      "mean              inf\n",
      "std               NaN\n",
      "min      0.000000e+00\n",
      "25%      5.224889e-01\n",
      "50%      1.708792e+00\n",
      "75%      1.042999e+03\n",
      "max               inf\n",
      "Name: followers_to_friends_ratio, dtype: float64\n",
      "followers_to_friends_ratio\n",
      "inf            5376\n",
      "0.000000        221\n",
      "1.000000         85\n",
      "0.500000         64\n",
      "0.333333         59\n",
      "               ... \n",
      "3528.268145       1\n",
      "602.938852        1\n",
      "1.043967          1\n",
      "1.221818          1\n",
      "450.684211        1\n",
      "Name: count, Length: 26700, dtype: int64\n",
      "\n",
      "Number of NA: 1034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eldricksim/Desktop/NUS/Year 4/Y4S1/BT4222/Project/bt4222/.venv/lib/python3.9/site-packages/pandas/core/nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n"
     ]
    }
   ],
   "source": [
    "df['followers_to_friends_ratio'] = df['followers_count'] / df['friends_count']\n",
    "print(df['followers_to_friends_ratio'].describe())\n",
    "print(df['followers_to_friends_ratio'].value_counts())\n",
    "print(f\"\\nNumber of NA: {df['followers_to_friends_ratio'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ratio of Followers_count to tweets per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    3.742300e+04\n",
      "mean              inf\n",
      "std               NaN\n",
      "min      0.000000e+00\n",
      "25%      4.651163e+01\n",
      "50%      2.173913e+02\n",
      "75%      2.794128e+03\n",
      "max               inf\n",
      "Name: followers_to_tweets_per_day_ratio, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eldricksim/Desktop/NUS/Year 4/Y4S1/BT4222/Project/bt4222/.venv/lib/python3.9/site-packages/pandas/core/nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n"
     ]
    }
   ],
   "source": [
    "df['followers_to_tweets_per_day_ratio'] = df['followers_count'] / df['average_tweets_per_day']\n",
    "print(df['followers_to_tweets_per_day_ratio'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ratio of friends to tweets per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    3.741100e+04\n",
      "mean              inf\n",
      "std               NaN\n",
      "min      0.000000e+00\n",
      "25%      1.927754e+01\n",
      "50%      1.250562e+02\n",
      "75%      4.652773e+02\n",
      "max               inf\n",
      "Name: friends_to_tweets_per_day_ratio, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eldricksim/Desktop/NUS/Year 4/Y4S1/BT4222/Project/bt4222/.venv/lib/python3.9/site-packages/pandas/core/nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n"
     ]
    }
   ],
   "source": [
    "df['friends_to_tweets_per_day_ratio'] = df['friends_count'] / df['average_tweets_per_day']\n",
    "print(df['friends_to_tweets_per_day_ratio'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         description  \\\n",
      "0  Blame @xaiax, Inspired by @MakingInvisible, us...   \n",
      "1  Photographing the American West since 1980. I ...   \n",
      "2  Scruffy looking nerf herder and @twitch broadc...   \n",
      "3  Wife.Godmother.Friend.Feline Fanatic! Assistan...   \n",
      "4               Loan coach at @mancity & Aspiring DJ   \n",
      "\n",
      "                     mentions  mention_count  \n",
      "0  [@xaiax, @MakingInvisible]              2  \n",
      "1                          []              0  \n",
      "2           [@twitch, @gmail]              2  \n",
      "3                          []              0  \n",
      "4                  [@mancity]              1  \n"
     ]
    }
   ],
   "source": [
    "def extract_mentions(description):\n",
    "    mentions = re.findall(r'@\\w+', str(description))\n",
    "    return mentions\n",
    "\n",
    "# Apply the function to the description column to create a new column with the mentions\n",
    "df['mentions'] = df['description'].apply(extract_mentions)\n",
    "\n",
    "# Feature: Count of mentions\n",
    "df['mention_count'] = df['mentions'].apply(len)\n",
    "\n",
    "# Display the dataframe with the new columns\n",
    "print(df[['description', 'mentions', 'mention_count' ]].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resolving NA in created features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['followers_to_friends_ratio'].fillna(0, inplace=True)\n",
    "df['followers_to_tweets_per_day_ratio'].fillna(0, inplace=True)\n",
    "df['friends_to_tweets_per_day_ratio'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight of Evidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How WOE works:\n",
    "Run the features you want to conduct weight of evidence on. For example, I put the features in temp_list and then created a dataframe containing only those features in df_tmp.\n",
    "\n",
    "* Step 1: Replace temp_list with your features\n",
    "* Step 2: Run code chunk below\n",
    "* Step 3: Look at the WOE score for each bin of each feature to interpret WOE results\n",
    "\n",
    "How to Interpret WOE scores\n",
    "Negative or Positive Values indicate the direction of the feature while the magnitude indicate the strength of the feature.\n",
    "E.g For the feature \"statuses_count\", if the woe score for one of its bin is 0.5 it indicates that for that bin, the feature \"statuses_count\" identifies many bots.\n",
    "Conversely if the woe score for one of its bin is -0.7, it means that the feature is not good a predicting bots.\n",
    "\n",
    "Also do look at the IV scores to determine the features contribution. Generally an IV of >0.02 indicates weak predictive power while >0.5 indicates strong predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating woe binning ...\n",
      "Binning for mention_count:\n",
      "        variable         bin  count  count_distr   good    bad   badprob  \\\n",
      "0  mention_count  [-inf,1.0)  31088     0.830386  19724  11364  0.365543   \n",
      "1  mention_count   [1.0,2.0)   3841     0.102596   3063    778  0.202551   \n",
      "2  mention_count   [2.0,inf)   2509     0.067017   2226    283  0.112794   \n",
      "\n",
      "        woe    bin_iv  total_iv breaks  is_special_values  \n",
      "0  0.148299  0.018694  0.149074    1.0              False  \n",
      "1 -0.670738  0.040137  0.149074    2.0              False  \n",
      "2 -1.362830  0.090243  0.149074    inf              False  \n",
      "Binning for favourites_count:\n",
      "           variable              bin  count  count_distr   good    bad  \\\n",
      "0  favourites_count    [-inf,3000.0)  22524     0.601635  11704  10820   \n",
      "1  favourites_count  [3000.0,5000.0)   2707     0.072306   2167    540   \n",
      "2  favourites_count     [5000.0,inf)  12207     0.326059  11142   1065   \n",
      "\n",
      "    badprob       woe    bin_iv  total_iv  breaks  is_special_values  \n",
      "0  0.480376  0.621151  0.250267  0.872914  3000.0              False  \n",
      "1  0.199483 -0.689845  0.029783  0.872914  5000.0              False  \n",
      "2  0.087245 -1.648062  0.592864  0.872914     inf              False  \n",
      "Binning for followers_count:\n",
      "          variable             bin  count  count_distr   good    bad  \\\n",
      "0  followers_count    [-inf,500.0)  20173     0.538838   9881  10292   \n",
      "1  followers_count  [500.0,1500.0)   4511     0.120493   3685    826   \n",
      "2  followers_count    [1500.0,inf)  12754     0.340670  11447   1307   \n",
      "\n",
      "    badprob       woe    bin_iv  total_iv  breaks  is_special_values  \n",
      "0  0.510187  0.740438  0.320829  0.903372   500.0              False  \n",
      "1  0.183108 -0.795746  0.064332  0.903372  1500.0              False  \n",
      "2  0.102478 -1.470308  0.518211  0.903372     inf              False  \n"
     ]
    }
   ],
   "source": [
    "temp_lst = ['favourites_count', 'followers_count','account_type','mention_count']\n",
    "\n",
    "#Transforming Bot/Human to 1s and 0s\n",
    "df['account_type'] = df['account_type'].replace({'bot': 1, 'human': 0})\n",
    "\n",
    "y = df['account_type']  \n",
    "X = df.drop(columns=['account_type'])  \n",
    "\n",
    "df_tmp = df[temp_lst]\n",
    "# Conduct the binning process using woebin\n",
    "bins = sc.woebin(df_tmp, y='account_type', bins = 5)\n",
    "\n",
    "# Display the binning information (optional to view WoE values per variable)\n",
    "for key in bins.keys():\n",
    "    print(f\"Binning for {key}:\")\n",
    "    print(bins[key])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis for `description` feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37438\n",
      "count    37438.000000\n",
      "mean        54.429163\n",
      "std         48.679166\n",
      "min          0.000000\n",
      "25%          7.000000\n",
      "50%         43.000000\n",
      "75%         96.000000\n",
      "max        160.000000\n",
      "Name: description, dtype: float64\n",
      "0        blame  inspired by  using cmu phonetic data to...\n",
      "1        photographing the american west since 1980 i s...\n",
      "2        scruffy looking nerf herder and  broadcaster\\n...\n",
      "3        wifegodmotherfriendfeline fanatic assistant pr...\n",
      "4                              loan coach at   aspiring dj\n",
      "                               ...                        \n",
      "37433    role stock taker past roles nanny sales assist...\n",
      "37434                       kingdom landlord freecornbread\n",
      "37435        bienvenid al twitter oficial de sergio dalma \n",
      "37436    just a good guy wrapped up in a bad system\\nac...\n",
      "37437                                                     \n",
      "Name: description, Length: 37438, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     label     score\n",
      "0  LABEL_1  0.714407\n",
      "1  LABEL_1  0.716920\n",
      "2  LABEL_1  0.740677\n",
      "3  LABEL_1  0.705628\n",
      "4  LABEL_1  0.678854\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "from transformers import pipeline\n",
    "\n",
    "# Preprocess the description column\n",
    "description = df['description'].fillna('').str.lower()\n",
    "description = description.str.replace(r'@\\w+', '', regex=True)\n",
    "description = description.str.replace(r'http\\S+', '', regex=True)\n",
    "description = description.str.replace('#', '', regex=True)\n",
    "description = description.str.replace(r'[^a-zA-Z0-9\\s]', '', regex=True)\n",
    "\n",
    "# Get description statistics\n",
    "print(len(description))\n",
    "description_lengths = description.apply(len)\n",
    "print(description_lengths.describe())\n",
    "print(description)\n",
    "\n",
    "# Initialise model\n",
    "model_name = 'bert-base-uncased'\n",
    "sentiment_model = pipeline('sentiment-analysis', model=model_name)\n",
    "\n",
    "# Get sentiment of the description\n",
    "sentiments = description.apply(lambda text: sentiment_model(text)[0])\n",
    "\n",
    "df1 = pd.DataFrame(sentiments.tolist())\n",
    "print(df1.head())\n",
    "# Takes 25 minutes to run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "37433    1\n",
       "37434    1\n",
       "37435    1\n",
       "37436    1\n",
       "37437    1\n",
       "Name: sentiment_label, Length: 37438, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add sentiment label to original df\n",
    "df1['label'].value_counts()\n",
    "df.loc[df1['label']== 'LABEL_1', 'account_type'].value_counts()\n",
    "df['sentiment_label'] = df1['label'].map({'LABEL_0': 0, 'LABEL_1': 1})\n",
    "df['sentiment_label']\n",
    "# Label 0 = Negative, Label 1 = Positive"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
