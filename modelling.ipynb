{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "from hyperopt import hp\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from lmf import LoadModelFunction\n",
    "modeling = LoadModelFunction()\n",
    "\n",
    "from utils import mpr_report, mpr_report_en, final_fitting\n",
    "from utils2 import calc_iv, get_redundant_pairs, get_top_abs_correlations, roc_curve_graph,\\\n",
    "                    performance_table, plot_ks_graph, plot_deciles_performance, table_summary,\\\n",
    "                    remove_highcorr_vars, auc_by_groups, model_performance_metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"..\")\n",
    "\n",
    "predictive_cols = [\" \"] #all features\n",
    "target = \"target\"\n",
    "features = predictive_cols\n",
    "\n",
    "predictive_cols = pd.read_csv(\"feature importance\")\n",
    "predictive_cols.columns = ['0','importance']\n",
    "predictive_cols = predictive_cols[predictive_cols['importance'] > 0.02]\n",
    "\n",
    "train_x = df[df['X_fold'].isin(['train','valid'])][features]\n",
    "train_y = df[df['X_fold'].isin(['train','valid'])][target]\n",
    "\n",
    "test_x = df[df['X_fold'] == 'test'][features]\n",
    "test_y = df[df['X_fold'] == 'test'][target]\n",
    "\n",
    "serach_space = {\n",
    "    'k_folds': 5\n",
    "    'k_split': 'non_ts',\n",
    "\n",
    "    'f_method': hp.choice('f_method',['all']),\n",
    "    'num_feats': hp.choice('num_feats',[#insert number of features here]),\n",
    "\n",
    "    'scaler': hp.choice('scaler',['noscaler']),\n",
    "\n",
    "    'SEED': 2024    \n",
    "}\n",
    "\n",
    "hyperopt_file = #directory to hyperopt file\n",
    "bestLoss, bestParams, results = modeling.load_result(hyperopt_file)\n",
    "results_df = pd.DataFrame(results).T.reset_index().rename(columns={'index':'Precision'})\n",
    "results_df = results_df[['f_method', 'num_feats'] + \\\n",
    "                        [i for i in results_df.columns if i not in ['f_method','num_feats','Precision']] + \\\n",
    "                            ['Precision']].rename(columns = {'f_method': 'Feature selection method', 'num_feats': 'Num of Features'})\n",
    "del results_df['m_method']\n",
    "del results_df['k_folds']\n",
    "del results_df['SEED']\n",
    "del results_df['k_split']\n",
    "results_df['Precision'] = -results_df['Precision']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    'lgbm': {\n",
    "        'n_estimators': hp.choice('n_estimators', [1000]),\n",
    "        'learning_rate': hp.choice('n_estimators', [0.1]),\n",
    "        'num_leaves': hp.choice('num_leaves',[50]),\n",
    "        'max_depth': hp.choice('max_depth',[5]),\n",
    "        'reg_alpha': hp.choice('reg_alpha',[0.1]),\n",
    "        'reg_lambda': hp.choice('reg_lambda',[0.1]),\n",
    "        'colsample_bytree': hp.choice('colsample_bytree',[1.0]),\n",
    "        'subsample': hp.choice('subsample', [1.0])\n",
    "    }\n",
    "}\n",
    "\n",
    "def run_model(X, y, search_space, model_type, model_config, model_dir, num_trials):\n",
    "    search_space_updated = search_space.copy()\n",
    "    search_space_updated['m_method'] = hp.choice('m_method', model_type)\n",
    "    search_space_updated.update(model_config[model_type[0]])\n",
    "    hyperopt_file = #directory to hyperopt_file\n",
    "\n",
    "    modeling.hyperparameter_tuning(X,y num_trials, hyperopt_file, search_space_updated)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if it works\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(penalty = 'l1', C=0.9, solver = 'saga', n_jobs= -1)\n",
    "lr.fit(train_x, train_y)\n",
    "\n",
    "model_type = ['lgbm']\n",
    "\n",
    "run_model(test_x, test_y, search_space, model_type, model_config, model_dir, 10)\n",
    "\n",
    "threshold_list = [0.8,0.85,0.9,0.91,0.92,0.93,0.94,0.95,0.96,0.97,0.98,0.99]\n",
    "\n",
    "model_list = ['lgbm']\n",
    "list_of_sample = [['test'],['outoftime'],['test', 'outoftime']]\n",
    "\n",
    "score_df = final_fitting(modeling, model_dir, model_list, df, features, target, non_predictive_cols)\n",
    "\n",
    "mpr_all = mpr_report(model_list,[['test'],['outoftime'],['test','outoftime']], threshold_list, score_df, target)\n",
    "mpr_all.tocsv('save to dir')\n",
    "\n",
    "model_list = ['lgmb']\n",
    "features_df = pd.DataFrame({'features': list(predictive_cols['0'])})"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
